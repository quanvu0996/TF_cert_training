{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8qpAznwl3Fk"
      },
      "source": [
        "ver 6.0 \n",
        "Supervised contrastive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRXKKOy-8X1R"
      },
      "source": [
        "# Enviroment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7sPzaTKcdTo",
        "outputId": "e45c9883-58bb-4e7e-b632-d0181821332d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 10.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.21.6)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.2)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.2)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n",
            "Installing collected packages: locket, partd, fsspec\n",
            "Successfully installed fsspec-2022.5.0 locket-1.0.0 partd-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons\n",
        "# !pip install recommenders\n",
        "!pip install \"dask[dataframe]\" --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGKXb_a2GGDk"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XS6UHXPVAQqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "import gc\n",
        "import math\n",
        "import datetime, time\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.losses import TripletSemiHardLoss \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# from recommenders.datasets.python_splitters import python_random_split\n",
        "# from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
        "# from recommenders.models.cornac.cornac_utils import predict_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gv8gXemwD3UQ",
        "outputId": "6188aba1-18b2-42e8-e6fa-fd026a2fe37a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Crhty6fiAQqu"
      },
      "outputs": [],
      "source": [
        "itemCol = 'movieId'\n",
        "userCol = 'userId'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOJJy441A0w0",
        "outputId": "50917d60-b02f-4ce5-dfa6-a18648cd3405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# DGX setup\n",
        "# fpath = \"./ml-20m\"\n",
        "\n",
        "#colab setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "fpath = \"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/ml-20m\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_DH8SxPH64nZ",
        "outputId": "54c6673c-716e-46a3-df9e-9d112bd583ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                        title  \\\n",
              "0        1                    Toy Story   \n",
              "1        2                      Jumanji   \n",
              "2        3             Grumpier Old Men   \n",
              "3        4            Waiting to Exhale   \n",
              "4        5  Father of the Bride Part II   \n",
              "\n",
              "                                        genres  year  \n",
              "0  Adventure Animation Children Comedy Fantasy  1995  \n",
              "1                   Adventure Children Fantasy  1995  \n",
              "2                               Comedy Romance  1995  \n",
              "3                         Comedy Drama Romance  1995  \n",
              "4                                       Comedy  1995  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-579850fd-168b-4629-b712-ea7d81f7b812\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Adventure Animation Children Comedy Fantasy</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>Adventure Children Fantasy</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>Comedy Romance</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Comedy Drama Romance</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-579850fd-168b-4629-b712-ea7d81f7b812')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-579850fd-168b-4629-b712-ea7d81f7b812 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-579850fd-168b-4629-b712-ea7d81f7b812');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Loading movie\n",
        "movies = pd.read_csv(fpath+'/movies.csv')\n",
        "movies[\"year\"]=movies[\"title\"].apply(lambda x: x[-5:-1])\n",
        "movies[\"genres\"] = movies[\"genres\"].apply(lambda x: ' ' if x == '(no genres listed)' else ' '.join(x.split('|')) )\n",
        "movies[\"title\"]= movies[\"title\"].apply(lambda x: x[0:-7])\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fiRtTNy1ScIa"
      },
      "outputs": [],
      "source": [
        "# user-wise train-test split\n",
        "def user_wise_split(userCol, test_size=0.25):\n",
        "    df = pd.read_csv(fpath+'/ratings.csv')\n",
        "    df[\"y\"] = df[\"rating\"]/2.5-1\n",
        "    all_user = df[userCol].drop_duplicates()\n",
        "    train_user, test_user = train_test_split(all_user, test_size=test_size)\n",
        "\n",
        "    train_ratings = df[df[userCol].isin(train_user)]\n",
        "    test_ratings = df[df[userCol].isin(test_user)]\n",
        "    return train_ratings, test_ratings\n",
        "\n",
        "train, test= user_wise_split(userCol,test_size= 0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iejmAYEB4kjy"
      },
      "outputs": [],
      "source": [
        "top_k_item = 20000\n",
        "wu_size = 200\n",
        "max_item = wu_size\n",
        "\n",
        "top_items = train.groupby(itemCol).count().sort_values(by=userCol, ascending=False).head(top_k_item).index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfY6FeqKqQ4"
      },
      "source": [
        "# Class  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "mvnW0Fd52VkU"
      },
      "outputs": [],
      "source": [
        "class TimeTrachker():\n",
        "    \"\"\"Tracking runing time\"\"\"\n",
        "    def start(self):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def check(self, des = ''):\n",
        "        try:\n",
        "            if self.check_time is None:\n",
        "                self.check_time = self.start_time\n",
        "        except:\n",
        "            self.check_time = self.start_time\n",
        "        self.end_time = time.time()\n",
        "        dur = self.end_time - self.check_time\n",
        "        print(des + \" duration: \", dur)\n",
        "\n",
        "        self.check_time = time.time()\n",
        "        return dur\n",
        "\n",
        "    def stop(self, des = ''):\n",
        "        self.end_time = time.time()\n",
        "        dur = self.end_time - self.start_time\n",
        "        print(des + \" duration: \", dur)\n",
        "        self.start_time = time.time()\n",
        "        self.check_time = None\n",
        "        return dur\n",
        "\n",
        "timer = TimeTrachker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Lb2Hx2rlWzmP"
      },
      "outputs": [],
      "source": [
        "def get_interaction_set(interaction, max_item = None, top_k_item = None):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        interaction: df[userCol, itemCol, y]: dữ liệu đầu vào\n",
        "        max_item: int: item num limit\n",
        "    Output:\n",
        "        df, itemCol: list, y: list, itemCol_str: string, userCol as index\n",
        "        list item sắp xếp theo giảm dần độ lớn rating\n",
        "    \"\"\"\n",
        "    items = interaction.groupby(itemCol).count().sort_values(by=userCol, ascending=False)\n",
        "    if top_k_item is not None:\n",
        "        top_items = items.head(top_k_item).index\n",
        "        interaction = interaction[interaction[itemCol].isin(top_items)]\n",
        "    else:\n",
        "        top_items = items.index\n",
        "\n",
        "    # Sắp xếp item theo thứ tự giảm dần rating (về sau cắt padding sẽ ưu tiên giữ lại item có rating cao)\n",
        "    rindex = interaction.groupby(userCol)[\"y\"].transform(lambda grp: grp.sort_values(ascending=False).index)\n",
        "    interaction = interaction.reindex(rindex)\n",
        "    \n",
        "    # Chuyển thành warm-up set theo từng user\n",
        "    interaction = interaction.groupby(\"userId\").agg({itemCol:list, \"y\":list})\n",
        "\n",
        "    # Giới hạn độ dài warm_up size\n",
        "    if max_item is not None:\n",
        "        interaction[itemCol] = interaction[itemCol].apply(lambda x: x[0:max_item])\n",
        "        interaction[\"y\"] = interaction[\"y\"].apply(lambda x: x[0:max_item])\n",
        "\n",
        "    return interaction, top_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "jJySyZdU4Iou"
      },
      "outputs": [],
      "source": [
        "# Bulding model\n",
        "class Efficient_Rec(tf.keras.Model):\n",
        "    def __init__(self, encoder, wu_size= 200, use_tf_function=False):\n",
        "        super().__init__()\n",
        "        self.use_tf_function = use_tf_function\n",
        "        self.encoder = encoder\n",
        "        self.wu_size = wu_size\n",
        "\n",
        "    # from v2.2: chỉ groupby, không padding\n",
        "    @staticmethod\n",
        "    def get_interaction_set(interaction, max_item = None, top_k_item = None):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            interaction: df[userCol, itemCol, y]: dữ liệu đầu vào\n",
        "            max_item: int: item num limit\n",
        "        Output:\n",
        "            df, itemCol: list, y: list, itemCol_str: string, userCol as index\n",
        "            list item sắp xếp theo giảm dần độ lớn rating\n",
        "        \"\"\"\n",
        "        items = interaction.groupby(itemCol).count().sort_values(by=userCol, ascending=False)\n",
        "        if top_k_item is not None:\n",
        "            top_items = items.head(top_k_item).index\n",
        "            interaction = interaction[interaction[itemCol].isin(top_items)]\n",
        "        else:\n",
        "            top_items = items.index\n",
        "\n",
        "        # Sắp xếp item theo thứ tự giảm dần rating (về sau cắt padding sẽ ưu tiên giữ lại item có rating cao)\n",
        "        rindex = interaction.groupby(userCol)[\"y\"].transform(lambda grp: grp.sort_values(ascending=False).index)\n",
        "        interaction = interaction.reindex(rindex)\n",
        "        \n",
        "        # Chuyển thành warm-up set theo từng user\n",
        "        interaction = interaction.groupby(\"userId\").agg({itemCol:list, \"y\":list})\n",
        "\n",
        "        # Giới hạn độ dài warm_up size\n",
        "        if max_item is not None:\n",
        "            interaction[itemCol] = interaction[itemCol].apply(lambda x: x[0:max_item])\n",
        "            interaction[\"y\"] = interaction[\"y\"].apply(lambda x: x[0:max_item])\n",
        "\n",
        "        return interaction, top_items\n",
        "\n",
        "    def _preprocess(self, inputs, padding_size = 100):\n",
        "        \"\"\"\n",
        "        Padding về wu_size và mask_size, convert list of items => string of items\n",
        "        batch_inputs: df: itemStr, y\"\"\"\n",
        "\n",
        "        def padding_list(list_item, wu_size, value=0, is_padding=True):\n",
        "            series_item1 = list_item[0:wu_size]\n",
        "            if is_padding:\n",
        "                series_item1 = series_item1+[value]*(wu_size-len(series_item1))\n",
        "            return series_item1\n",
        "\n",
        "        items_list, ratings_list = inputs\n",
        "\n",
        "        items   = items_list.apply(lambda x: ' '.join(list([str(i) for i in x])))\n",
        "        ratings =   np.stack( ratings_list.apply(lambda x: padding_list( x, padding_size  ) ) )\n",
        "\n",
        "        return items, ratings\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_top_cluster(scores, interaction_list):\n",
        "        interaction_list_ = interaction_list.copy()\n",
        "        idx = np.argsort(-scores.transpose(),axis=0)[:cluster_num]\n",
        "        interaction_list_[\"clusters\"] = [list(i) for i in idx.transpose()]\n",
        "        interaction_list_[\"scores\"] = [ list(scores[i][ind]) for i, ind in enumerate(idx.transpose()) ]\n",
        "        return interaction_list_\n",
        "\n",
        "    def minibatch_clustering(self, interaction_list, batch_size= 512):\n",
        "        chunks = [interaction_list[i:i+batch_size] for i in range(0,interaction_list.shape[0],batch_size)]\n",
        "        preds = []\n",
        "        for chunk in chunks:\n",
        "            pred = self.encoder(self._preprocess( [chunk[itemCol], chunk[\"y\"]], padding_size = wu_size )).numpy()\n",
        "            preds.append( pred )\n",
        "\n",
        "        return np.concatenate(preds)\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_explode(ratings, batch_size = 1024**2):\n",
        "        chunks = [ratings[i:i+batch_size] for i in range(0,ratings.shape[0],batch_size)]\n",
        "        explodes = []\n",
        "\n",
        "        # Todo: convert for loop to parallel\n",
        "        def chunk_process(chunk):\n",
        "            explode = chunk.explode([\"clusters\", \"scores\"])\n",
        "            explode[\"contribute_score\"] = explode[\"scores\"].astype(\"float64\")*explode[\"y\"]\n",
        "            explode = explode.groupby([\"clusters\", \"movieId\"]).agg({\n",
        "                \"contribute_score\": [\"mean\", \"count\"]\n",
        "            }).reset_index()\n",
        "            explode.columns = [\"clusters\", \"movieId\", \"mean\", \"count\"]\n",
        "\n",
        "            return explode\n",
        "\n",
        "        explodes = Parallel(n_jobs = -1, verbose = 1)(\n",
        "                    delayed(chunk_process)(chunk) for chunk in tqdm(chunks))\n",
        "        # combine results\n",
        "        gr = pd.concat(explodes, axis = 0)\n",
        "        gr[\"product\"] = gr[\"mean\"]*gr[\"count\"]\n",
        "        gr = gr.groupby([\"clusters\", \"movieId\"]).sum().reset_index()\n",
        "        gr[\"contribute_score\"] = gr[\"product\"]/gr[\"count\"]\n",
        "        gr = gr[[\"clusters\", \"movieId\", \"contribute_score\"]]\n",
        "        return gr\n",
        "\n",
        "    def get_shortlist(self, ratings, interaction_list= None, limit = 500, cluster_num = 5, batch_size=512):\n",
        "        timer.start()\n",
        "        if interaction_list is None:\n",
        "            interaction_list_, _ = self.get_interaction_set(  ratings, max_item = max_item, top_k_item = top_k_item  )\n",
        "        else:\n",
        "            interaction_list_ = interaction_list.copy()\n",
        "\n",
        "        scores = self.minibatch_clustering(interaction_list_, batch_size=batch_size)\n",
        "\n",
        "        # Limit number of cluster for each user\n",
        "        interaction_list_ = self.get_top_cluster(scores, interaction_list_)\n",
        "        timer.check(des = \"Get cluster\")\n",
        "\n",
        "        # Get shortlist for each cluster\n",
        "        ratings_ = ratings.copy().set_index(\"userId\")\n",
        "        ratings_ = ratings_[ratings_[\"y\"]>0]\n",
        "        ratings_ = ratings_.join(interaction_list_, rsuffix=\"_l\", how = \"inner\")\n",
        "        timer.check(des = \"Join interaction\")\n",
        "        ratings_ = self.chunk_explode(ratings_, batch_size= 1024*200)\n",
        "        timer.check(des = \"Chunk explode\")\n",
        "\n",
        "        ratings_[\"rank\"] = ratings_.groupby(\"clusters\")[\"contribute_score\"].rank(method='first', ascending=False)\n",
        "        ratings_ = ratings_[(ratings_[\"rank\"] <= limit)&(ratings_[\"contribute_score\"]>0)]\n",
        "        timer.check(des = \"Chunk explode\")\n",
        "\n",
        "        self.shortlist = ratings_\n",
        "\n",
        "        timer.stop(des = \"Total\")\n",
        "\n",
        "    @staticmethod\n",
        "    def left_anti_user_item_join( left, right ):\n",
        "        \"\"\"Fast left anijoin 2 dataframe by one column\"\"\"\n",
        "        wu_key = left[userCol].astype('str')+\"&\"+left[itemCol].astype('str')\n",
        "        blacklist = right[userCol].astype('str')+\"&\"+right[itemCol].astype('str')\n",
        "\n",
        "        key_diff = set(wu_key).difference(blacklist)\n",
        "        where_diff = wu_key.isin(key_diff)\n",
        "        output = left[where_diff]\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def batch_get_recommend(self, warm_up= None, historical_ratings = None, top_k = 10, is_remove_interacted = True, \n",
        "        batch_size=1024, reduce_method=\"random\", using_rapids= False):\n",
        "        \"\"\"\n",
        "        reduce_method: str, 'random' or 'mean'\n",
        "        \"\"\"\n",
        "        print(\"historical_ratings shape \", historical_ratings.shape)\n",
        "        timer.start()\n",
        "        if warm_up is None:\n",
        "            warm_up, _ = self.get_interaction_set( \n",
        "                         historical_ratings\n",
        "                        , max_item = max_item\n",
        "                        , top_k_item = top_k_item )\n",
        "\n",
        "        scores = self.minibatch_clustering(warm_up, batch_size=512)\n",
        "        wu = self.get_top_cluster( scores, warm_up)\n",
        "\n",
        "        wu = wu.explode([\"clusters\", \"scores\"]).reset_index()[[userCol, \"clusters\", \"scores\"]]\n",
        "        timer.check(des = \"Get cluster for user\")\n",
        "        print(\"wu shape \", wu.shape)\n",
        "        \n",
        "        user_num = wu[userCol].drop_duplicates().shape[0]\n",
        "        print(\"user_num \", user_num)\n",
        "\n",
        "        # cudf.from_pandas\n",
        "        if using_rapids:\n",
        "            wu = dd.from_pandas(wu)\n",
        "            historical_ratings = dd.from_pandas(historical_ratings.copy())\n",
        "\n",
        "        chunks = [wu[wu[userCol].isin(range(i,i+batch_size))] \n",
        "                  for i in range(0,user_num,batch_size)]\n",
        "\n",
        "        his_chunks = [historical_ratings[historical_ratings[userCol].isin(range(i,i+batch_size))] \n",
        "                        for i in range(0,user_num,batch_size)]\n",
        "       \n",
        "        shortlist = self.shortlist\n",
        "\n",
        "        def batch_join_process(chunk, his_chunk):\n",
        "            timer2 = TimeTrachker()\n",
        "            timer2.start()\n",
        "\n",
        "            wu = chunk.merge(shortlist, on=\"clusters\", how='inner')\n",
        "            print('''wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape: ''', wu.shape)\n",
        "            wu[\"matched_score\"] = wu[\"scores\"]*wu[\"contribute_score\"]\n",
        "\n",
        "            if reduce_method==\"mean\":\n",
        "                wu = wu.groupby([userCol, itemCol]).agg({\"matched_score\":'mean'}).reset_index()\n",
        "            \n",
        "            if reduce_method==\"random\":\n",
        "                # using drop_duplicates for boost speed, may reduce accuracy.\n",
        "                wu = wu.drop_duplicates(subset=[\"userId\", \"movieId\"])\n",
        "\n",
        "            print('''after reduce wu shape: ''', wu.shape)\n",
        "            timer2.check(des = \"reduce\")\n",
        "\n",
        "            if is_remove_interacted:\n",
        "                wu = self.left_anti_user_item_join( wu, historical_ratings )\n",
        "\n",
        "            print('''after remove interacted wu shape: ''', wu.shape)\n",
        "            timer2.check(des = \"remove interacted item\")\n",
        "\n",
        "            wu[\"rank\"] = wu.groupby(userCol)[\"matched_score\"].rank(method='first', ascending=False)\n",
        "            wu = wu[wu[\"rank\"]<= top_k]\n",
        "\n",
        "            timer2.stop(des = \"all chunk processing time\")\n",
        "\n",
        "            return wu \n",
        "        \n",
        "        timer.check(des = \"Prepare to join\")\n",
        "        wus = Parallel(n_jobs = -1, backend= 'threading', verbose = 1)(\n",
        "                    delayed(batch_join_process)(chunk, his_chunk) for chunk, his_chunk in tqdm(zip(chunks, his_chunks)))\n",
        "        \n",
        "        gc.collect()\n",
        "\n",
        "        timer.check(des = \"Join\")\n",
        "\n",
        "        output = pd.concat(wus, axis=0)\n",
        "\n",
        "        timer.stop(des = \"Total\")\n",
        "        return output\n",
        "\n",
        "    def release_cache(self):\n",
        "        self.interaction_list = None \n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbp1tH7yUeI6"
      },
      "source": [
        "# Xây dựng encoder model\n",
        "Encoder =  interaction embedding + user feature embedding<br> \n",
        "interaction embedding = sum( interaction embedding các item i)<br> \n",
        "interaction embedding item i = rating x (embedding id sản phẩm + embedding item feature)<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxNyuo9-WJJG",
        "outputId": "c00bcbca-fa0a-40ec-ddb8-142d8db4c641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.95 s, sys: 355 ms, total: 5.3 s\n",
            "Wall time: 5.67 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Vectorize (encode + padding) item list\n",
        "max_vocab_size = len(top_items) # nếu số item có <= top_k_item => lấy số lượng item max\n",
        "items_str = ' '.join([str(i) for i in top_items])\n",
        "itemStr = itemCol+\"_str\"\n",
        "\n",
        "vectorizer = layers.TextVectorization( max_tokens= top_k_item, split='whitespace', output_sequence_length= wu_size, name = 'vectorizer')\n",
        "vectorizer.adapt( [items_str] ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "1U7EQG6zWpi9"
      },
      "outputs": [],
      "source": [
        "class Broadcasting_Multiply(tf.keras.layers.Layer):\n",
        "    \"\"\"Nhân 2 layers khác shape với nhau, trong đó:\n",
        "    inputs=[layer1, layer2]\n",
        "    layer1.shape = (None, n_item, n_feature)\n",
        "    layer2.shape = (None, n_item)\n",
        "    (Chú ý đúng thứ tự)\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, y = inputs\n",
        "        deno = tf.expand_dims(tf.cast(tf.math.count_nonzero(y, axis=1), tf.float32), -1)\n",
        "        #we add the extra dimension:\n",
        "        y = K.expand_dims(y, axis=-1)\n",
        "        #we replicate the elements\n",
        "        y = K.repeat_elements(y, rep=x.shape[2], axis=-1)\n",
        "\n",
        "        return x * y, deno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "--fbIsGLXjPD"
      },
      "outputs": [],
      "source": [
        "# Xây dựng mạng\n",
        "embedding_size = 173\n",
        "reps_size = 132\n",
        "cluster_num = 43\n",
        "\n",
        "@tf.function\n",
        "def avg_layer(z):\n",
        "    t = K.sum(z[0], axis=1)/z[1]\n",
        "    t = tf.clip_by_value( t, -1, 1 )\n",
        "    t = tf.where(tf.math.is_nan(t), tf.zeros_like(t), t)\n",
        "    return t\n",
        "\n",
        "\n",
        "def interaction_embedding():\n",
        "\n",
        "    input_wi = layers.Input(shape=(1,), name='input_wi')\n",
        "    wi = vectorizer(input_wi)\n",
        "    wi = layers.Embedding(input_dim= max_vocab_size, output_dim= embedding_size, mask_zero= True, name='ei')(wi)\n",
        "    # wi = layers.Dense(embedding_size, activation='sigmoid', use_bias = False, name='di')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='relu', use_bias = False, name='di1')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='relu', use_bias = False, name='di2')(wi)\n",
        "    # wi = layers.Dense(embedding_size, activation='sigmoid', use_bias = False, name='di3')(wi)\n",
        "\n",
        "    wr = layers.Input(shape=(wu_size,), name='warm_up_ratings')\n",
        "\n",
        "    ireps = Broadcasting_Multiply(name='mul')([wi, wr])\n",
        "    uprofile = layers.Lambda(lambda z: avg_layer(z) )(ireps)\n",
        "\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du1')(uprofile)\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du2')(uprofile)\n",
        "    # uprofile = layers.Dense( reps_size, activation='relu', name='du3')(uprofile)\n",
        "    # uprofile = layers.BatchNormalization(name='norm')(uprofile)\n",
        "    uprofile = layers.LayerNormalization(name='norm')(uprofile)\n",
        "    # uprofile = layers.Dense( reps_size, activation='relu', name='du4')(uprofile)\n",
        "    uprofile = layers.Dense(cluster_num, activation='sigmoid', name='clustering')(uprofile)\n",
        "    \n",
        "    \n",
        "    model = tf.keras.Model(inputs= [input_wi, wr], outputs=[uprofile])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "a7EW-lg9Cfi5"
      },
      "outputs": [],
      "source": [
        "# # Example of layer interaction embedding step by step\n",
        "# input_wi = [\"15 25 65 20 84\",  # 5 items\n",
        "#             \"51 54 45 21 24 83 81 76 74 75 72 48 29 38\",# 14 items\n",
        "#             \" \", # 0 item\n",
        "#             ] \n",
        "\n",
        "# tvectorizer = layers.TextVectorization( max_tokens= 17, split='whitespace', output_sequence_length= 10)\n",
        "# tvectorizer.adapt( input_wi ) \n",
        "\n",
        "# wi = tvectorizer(input_wi)\n",
        "# print(\"afer TextVectorization layer \\n\",wi)\n",
        "# wi = layers.Embedding(input_dim= 17, output_dim= 4, mask_zero= True, name='ei')(wi)\n",
        "# print(\"afer Embedding layer \\n\",wi)\n",
        "# wi = layers.Dense(3, activation='sigmoid',  use_bias = False, name='di')(wi)\n",
        "\n",
        "# wr = np.array([[0.5, 0.1, -0.5, 1, 0.25, 0, 0, 0, 0, 0], [0.25, 0.15, 0.5, 1, 0.25, 0.5, 0.1, -0.9, 0.4, -0.3], [0,0,0,0,0,0,0,0,0,0]])\n",
        "\n",
        "# ireps = Broadcasting_Multiply(name='mul')([wi, wr])\n",
        "# print(\"afer Multiply layer \\n\",ireps)\n",
        "# uprofile = layers.Lambda(lambda z: avg_layer(z) )(ireps)\n",
        "# print(\"afer Average layer \\n\",uprofile)\n",
        "\n",
        "# uprofile = layers.Dense( reps_size, activation='relu', name='du2')(uprofile)\n",
        "# uprofile = layers.LayerNormalization(name='norm')(uprofile)\n",
        "# uprofile = layers.Dense(5, activation='sigmoid', name='clustering')(uprofile)\n",
        "# print(\"afer Sigmoid layer \\n\",uprofile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "cJMxOoxzXvr_"
      },
      "outputs": [],
      "source": [
        "# Kiểm tra tham số\n",
        "# interaction_embedding().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "PuAM8w01Xy93"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model( interaction_embedding() ,show_shapes=True, show_dtype=True, show_layer_names=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BISfMUNM37ug"
      },
      "source": [
        "# Evaluate model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "83VIKSPGNrN6"
      },
      "outputs": [],
      "source": [
        "def model_evaluate(model, movies, df):\n",
        "    dfu, ttop_items = get_interaction_set( df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    group_scores = model.encoder(model._preprocess( [dfu[itemCol], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "\n",
        "    print(\"SAMPLE INTERACTION EMBEDDING\")\n",
        "    print( np.max(group_scores), np.mean(group_scores), np.min(group_scores) )\n",
        "    print( group_scores[0:3] )\n",
        "\n",
        "    print(\"FEATURE PLOT\")\n",
        "    feature_plot( movies, df, group_scores)\n",
        "    \n",
        "    print(\"CLUSTER CHECKING\")\n",
        "    check_cluster(group_scores)\n",
        "    \n",
        "    print(\"SPECTROGRAM PLOT\")\n",
        "    plot_spectrogram(group_scores)\n",
        "\n",
        "def get_label(movies, df, is_encode = False):\n",
        "    movies[\"genres_list\"] = movies[\"genres\"].apply(lambda x: x.split(' '))\n",
        "    movie_genres = movies.explode(\"genres_list\")\n",
        "    gr = df.merge(movie_genres, on=\"movieId\").groupby([\"userId\", \"genres_list\"])[\"movieId\"].count().reset_index()\n",
        "    gr[\"rank\"] = gr.groupby(\"userId\")[\"movieId\"].rank(method='first', ascending=False)\n",
        "\n",
        "    labels = gr[gr[\"rank\"] ==1].set_index(\"userId\")\n",
        "    # labels[\"pred_max_ind\"] = np.argmax(group_scores, axis=1)\n",
        "\n",
        "    if is_encode:\n",
        "        label_enc = LabelEncoder()\n",
        "        labels[\"label\"] = label_enc.fit_transform(labels[\"genres_list\"])\n",
        "\n",
        "    return labels\n",
        "\n",
        "def feature_plot( movies, df, group_scores ):\n",
        "    tlabels = get_label(movies, df)\n",
        "\n",
        "    tsne = PCA(n_components=2, random_state=123)\n",
        "    # tsne = TSNE(n_components=2, random_state=123)\n",
        "    z = tsne.fit_transform(group_scores) \n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y\"] = tlabels[\"genres_list\"]\n",
        "    df[\"comp-1\"] = z[:,0]\n",
        "    df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (8,8)\n",
        "    sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                    palette=\"Paired\" ,#sns.color_palette(\"hls\", 3),\n",
        "                    data=df)#.set(title=\"Iris data T-SNE projection\") \n",
        "    plt.show()\n",
        "\n",
        "def check_cluster(group_scores):\n",
        "    # Kiểm tra số user trong mỗi cụm có bị vón cục\n",
        "    ugs= np.argmax(group_scores, axis=1)\n",
        "    for i in range(50):\n",
        "        print(i,': ', np.sum(ugs==i) )\n",
        "\n",
        "def plot_spectrogram(group_scores):\n",
        "    # Sort theo user_group + draw sigmoid/softmax layer\n",
        "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "    k =100\n",
        "    a = group_scores\n",
        "    ind = np.argmax(group_scores, axis=1)\n",
        "    plt.imshow( a[np.argsort(ind)][0:k] )\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_cs4Ci70vrkA"
      },
      "outputs": [],
      "source": [
        "def model_plot(model, movies, df):\n",
        "    dfu, ttop_items = get_interaction_set( df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    group_scores = model.encoder(model._preprocess( [dfu[itemCol], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "    print(\"FEATURE PLOT\")\n",
        "    feature_plot( movies, df, group_scores)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfUOMI8subTw"
      },
      "source": [
        "# Warm start user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQtBh9xFunkU",
        "outputId": "5c1e8250-c6af-494b-cb9a-50b16a3a889f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37042, 4)\n",
            "CPU times: user 1.59 ms, sys: 0 ns, total: 1.59 ms\n",
            "Wall time: 1.61 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "u_train_from = 0\n",
        "u_train_to = u_train_from + 130000\n",
        "u_test = u_train_to + 5000\n",
        "\n",
        "def get_labeled_data(df):\n",
        "    interact_df, _ = get_interaction_set( \n",
        "                     df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    labels = get_label( movies, df, is_encode = True)\n",
        "    interact_df[\"label\"] = labels[\"label\"]\n",
        "    return interact_df[[\"movieId\",\"y\",\"label\"]]\n",
        "try:\n",
        "    train_warm\n",
        "except:\n",
        "    # if exists, do not rerun\n",
        "    train_warm =  get_labeled_data( train[(train[userCol]>u_train_from)&(train[userCol]<u_train_to)] )\n",
        "    train_warm[\"rating_num\"] = train_warm.apply(lambda x: len(x[\"y\"]), axis=1)\n",
        "    # pretrain with warm start user\n",
        "    train_warm = train_warm[train_warm[\"rating_num\"]>=100]\n",
        "\n",
        "print( train_warm.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "aGY_dv9cV3Br"
      },
      "outputs": [],
      "source": [
        "# x = train[[\"userId\", \"rating\"]].groupby(\"userId\").count()\n",
        "# x[\"rating_num_clip\"] = x[\"rating\"].clip(0, 700).apply(lambda x: int(x/20)*20)\n",
        "# x.groupby(\"rating_num_clip\").count().plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "uFZiUT4FXHqn"
      },
      "outputs": [],
      "source": [
        "# x.groupby(\"rating_num_clip\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE0hPo7UFNkV",
        "outputId": "7d3fa158-f632-4755-a14d-5ccc9b39bc26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1009"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wO4EX1_Z-h3"
      },
      "source": [
        "# supervised constrastive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "hQ-pwUZafD__"
      },
      "outputs": [],
      "source": [
        "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "TbltflgfUmXf"
      },
      "outputs": [],
      "source": [
        "# Thực hiện training\n",
        "def _supervised_constrastive_train_step(self, inputs):\n",
        "    items_pd, ratings_pd, labels = inputs[\"movieId\"], inputs[\"y\"], inputs[\"label\"]\n",
        "    items, ratings = self._preprocess((items_pd, ratings_pd), wu_size)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Interaction embedding\n",
        "        vec = self.encoder([items, ratings])\n",
        "\n",
        "        average_loss = self.loss(labels, vec)\n",
        "\n",
        "    # Apply an optimization step\n",
        "    variables = self.trainable_variables \n",
        "    gradients = tape.gradient(average_loss, variables)\n",
        "    \n",
        "    # Gradient clipping\n",
        "    # gradients = [None if gradient is None else tf.clip_by_value(gradient, -0.1, 0.1)\n",
        "    #              for gradient in gradients]\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "\n",
        "Efficient_Rec._supervised_constrastive_train_step = _supervised_constrastive_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "qSr05iptaPha"
      },
      "outputs": [],
      "source": [
        "# Thực hiện minibatch training\n",
        "def _spv_constrastive_train_minibatch_step(self, inputs, batch_size):\n",
        "    df = inputs.copy()\n",
        "    chunks = [df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]\n",
        "    losses = []\n",
        "    for chunk in chunks:\n",
        "        loss = self._supervised_constrastive_train_step(chunk)\n",
        "        losses.append(loss[\"batch_loss\"].numpy())\n",
        "        print(loss)\n",
        "        gc.collect()\n",
        "    return np.mean(losses)\n",
        "\n",
        "Efficient_Rec._spv_constrastive_train_minibatch_step = _spv_constrastive_train_minibatch_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "uBCoJlJMdB7y"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model = Efficient_Rec( encoder = interaction_embedding(), \n",
        "                      wu_size = wu_size,\n",
        "                      use_tf_function=False)\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate = 0.001),\n",
        "    loss= TripletSemiHardLoss() # SupervisedContrastiveLoss(temperature = 0.05),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It6_5yszGfK7"
      },
      "outputs": [],
      "source": [
        "# Load trained model\n",
        "latest = tf.train.latest_checkpoint(\"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/\")\n",
        "model.encoder.load_weights(latest)\n",
        "test_set = train[(train[userCol]>10000)&(train[userCol]<12500)]\n",
        "model_plot(model, movies, test_set )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "VoepslyXhaQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0419f3b-84db-4bd6-ec35-960e2ba39593"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 7.39 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Train new model\n",
        "# epochs= 6\n",
        "# test_set = train[(train[userCol]>10000)&(train[userCol]<12500)]\n",
        "# model_plot(model, movies, test_set )\n",
        "# for n in range(epochs):\n",
        "#   print(n, \"/\", epochs, \": \", model._spv_constrastive_train_minibatch_step(train_warm.sample(frac=1.), batch_size=512))\n",
        "#   model_plot(model, movies, test_set )\n",
        "#   gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "M9_P8ZBsFGJb"
      },
      "outputs": [],
      "source": [
        "# model.encoder.save_weights(\"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/encoder_v6\",save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ZZUCY20TSjFk"
      },
      "outputs": [],
      "source": [
        "# model_evaluate(model, movies, \n",
        "#                warm_up_mask[(warm_up_mask[userCol]>u_train_to)&(warm_up_mask[userCol]<=u_test)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgfpZRoGF1KK"
      },
      "source": [
        "# Pick item pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQtrddWcEaoY",
        "outputId": "3e9ec0bf-6147-4261-d9a3-6b1600d8a5e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get cluster duration:  42.458805561065674\n",
            "Join interaction duration:  2.2462124824523926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "  0%|          | 0/45 [00:00<?, ?it/s]\u001b[A[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "\n",
            "3it [26:12, 524.28s/it]\n",
            "\n",
            "  9%|▉         | 4/45 [00:16<03:21,  4.90s/it]\u001b[A\n",
            " 13%|█▎        | 6/45 [00:27<03:16,  5.03s/it]\u001b[A\n",
            " 18%|█▊        | 8/45 [00:37<03:10,  5.15s/it]\u001b[A\n",
            " 22%|██▏       | 10/45 [00:48<03:01,  5.19s/it]\u001b[A\n",
            " 27%|██▋       | 12/45 [00:58<02:50,  5.17s/it]\u001b[A\n",
            " 31%|███       | 14/45 [01:11<02:52,  5.57s/it]\u001b[A\n",
            " 36%|███▌      | 16/45 [01:21<02:36,  5.39s/it]\u001b[A\n",
            " 40%|████      | 18/45 [01:31<02:22,  5.28s/it]\u001b[A\n",
            " 44%|████▍     | 20/45 [01:41<02:11,  5.24s/it]\u001b[A\n",
            " 49%|████▉     | 22/45 [01:52<02:01,  5.28s/it]\u001b[A\n",
            " 53%|█████▎    | 24/45 [02:02<01:48,  5.17s/it]\u001b[A\n",
            " 58%|█████▊    | 26/45 [02:12<01:38,  5.20s/it]\u001b[A\n",
            " 62%|██████▏   | 28/45 [02:23<01:28,  5.19s/it]\u001b[A\n",
            " 67%|██████▋   | 30/45 [02:33<01:17,  5.19s/it]\u001b[A\n",
            " 71%|███████   | 32/45 [02:45<01:10,  5.39s/it]\u001b[A\n",
            " 76%|███████▌  | 34/45 [02:55<00:58,  5.34s/it]\u001b[A\n",
            " 80%|████████  | 36/45 [03:06<00:47,  5.27s/it]\u001b[A\n",
            " 84%|████████▍ | 38/45 [03:16<00:36,  5.28s/it]\u001b[A\n",
            " 89%|████████▉ | 40/45 [03:26<00:26,  5.22s/it]\u001b[A\n",
            " 93%|█████████▎| 42/45 [03:37<00:15,  5.21s/it]\u001b[A\n",
            "100%|██████████| 45/45 [03:47<00:00,  5.07s/it]\n",
            "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  4.1min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk explode duration:  251.65278577804565\n",
            "Chunk explode duration:  0.40967369079589844\n",
            "Total duration:  296.7740309238434\n",
            "CPU times: user 1min 31s, sys: 7.52 s, total: 1min 39s\n",
            "Wall time: 4min 57s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "model.get_shortlist( \n",
        "    ratings = train[train[userCol].isin(train_warm.index)],\n",
        "    interaction_list = train_warm,\n",
        "    limit = 250, \n",
        "    cluster_num = 5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "0EvrD1tOVkXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b71acf7-3766-4c4a-86b3-c63152831836"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2146"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "pO4O1LwBXrOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "b3174366-ddef-4759-de1f-7783cee672c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         clusters  movieId  contribute_score   rank\n",
              "1509            0     1559          0.999828   50.0\n",
              "1517            0     1568          0.999903   20.0\n",
              "1749            0     1830          0.999891   33.0\n",
              "3136            0     3226          0.999931    2.0\n",
              "3144            0     3234          0.999901   22.0\n",
              "...           ...      ...               ...    ...\n",
              "1002222        42   129415          0.656138  209.0\n",
              "1002231        42   129478          0.997053    3.0\n",
              "1002276        42   129913          0.713123  153.0\n",
              "1002291        42   130034          0.760635  104.0\n",
              "1002329        42   130506          0.657095  204.0\n",
              "\n",
              "[10750 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cb3b9ad9-a80e-4df6-b2ea-139c3caece60\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clusters</th>\n",
              "      <th>movieId</th>\n",
              "      <th>contribute_score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>0</td>\n",
              "      <td>1559</td>\n",
              "      <td>0.999828</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>0</td>\n",
              "      <td>1568</td>\n",
              "      <td>0.999903</td>\n",
              "      <td>20.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1749</th>\n",
              "      <td>0</td>\n",
              "      <td>1830</td>\n",
              "      <td>0.999891</td>\n",
              "      <td>33.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3136</th>\n",
              "      <td>0</td>\n",
              "      <td>3226</td>\n",
              "      <td>0.999931</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3144</th>\n",
              "      <td>0</td>\n",
              "      <td>3234</td>\n",
              "      <td>0.999901</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002222</th>\n",
              "      <td>42</td>\n",
              "      <td>129415</td>\n",
              "      <td>0.656138</td>\n",
              "      <td>209.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002231</th>\n",
              "      <td>42</td>\n",
              "      <td>129478</td>\n",
              "      <td>0.997053</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002276</th>\n",
              "      <td>42</td>\n",
              "      <td>129913</td>\n",
              "      <td>0.713123</td>\n",
              "      <td>153.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002291</th>\n",
              "      <td>42</td>\n",
              "      <td>130034</td>\n",
              "      <td>0.760635</td>\n",
              "      <td>104.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1002329</th>\n",
              "      <td>42</td>\n",
              "      <td>130506</td>\n",
              "      <td>0.657095</td>\n",
              "      <td>204.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10750 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb3b9ad9-a80e-4df6-b2ea-139c3caece60')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb3b9ad9-a80e-4df6-b2ea-139c3caece60 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb3b9ad9-a80e-4df6-b2ea-139c3caece60');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "model.shortlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "cwQnzbWCxd9u"
      },
      "outputs": [],
      "source": [
        "test_warm_up, test_mask = train_test_split(test, test_size= 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "a1MUU9bdHQAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d23a0d24-7fc2-4f25-87c4-fdb163c67fa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "historical_ratings shape  (2511611, 5)\n",
            "Get cluster for user duration:  44.69536876678467\n",
            "wu shape  (1488832, 3)\n",
            "user_num  34624\n",
            "Prepare to join duration:  0.685844898223877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s][Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (13985750, 6)\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (14534000, 6)\n",
            "after reduce wu shape:  (2111523, 7)\n",
            "reduce duration:  66.78919076919556\n",
            "after reduce wu shape:  (2194296, 7)\n",
            "reduce duration:  70.59790992736816\n",
            "after remove interacted wu shape:  (2111236, 7)\n",
            "remove interacted item duration:  25.917268753051758\n",
            "after remove interacted wu shape:  (2194102, 7)\n",
            "remove interacted item duration:  22.672724962234497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r4it [01:41, 25.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all chunk processing time duration:  101.36686682701111\n",
            "all chunk processing time duration:  101.632404088974\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (13717000, 6)\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (13523500, 6)\n",
            "after reduce wu shape:  (2041734, 7)\n",
            "reduce duration:  67.334712266922\n",
            "after reduce wu shape:  (2070948, 7)\n",
            "reduce duration:  77.73314476013184\n",
            "after remove interacted wu shape:  (2041523, 7)\n",
            "remove interacted item duration:  33.21745538711548\n",
            "after remove interacted wu shape:  (2070760, 7)\n",
            "remove interacted item duration:  23.669610738754272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [03:30, 30.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all chunk processing time duration:  109.26224088668823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all chunk processing time duration:  109.75094270706177\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (13577250, 6)\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (14265250, 6)\n",
            "after reduce wu shape:  (2049849, 7)\n",
            "reduce duration:  61.96706676483154\n",
            "after reduce wu shape:  (2153721, 7)\n",
            "reduce duration:  67.2908284664154\n",
            "after remove interacted wu shape:  (2049621, 7)\n",
            "remove interacted item duration:  25.530102014541626\n",
            "after remove interacted wu shape:  (2153516, 7)\n",
            "remove interacted item duration:  24.927603483200073\n",
            "all chunk processing time duration:  92.65264630317688\n",
            "all chunk processing time duration:  97.42126655578613\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (13158000, 6)\n",
            "after reduce wu shape:  (1986552, 7)\n",
            "reduce duration:  34.46856331825256\n",
            "after remove interacted wu shape:  (1986358, 7)\n",
            "remove interacted item duration:  13.789148569107056\n",
            "all chunk processing time duration:  52.362091302871704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   7 out of   7 | elapsed:  5.9min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Join duration:  356.72791600227356\n",
            "Total duration:  402.19811058044434\n",
            "CPU times: user 7min 5s, sys: 13.2 s, total: 7min 18s\n",
            "Wall time: 6min 42s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "# interaction_list = train_warm[train_warm.index<=3000]\n",
        "top_k = 50\n",
        "is_remove_interacted = True\n",
        "\n",
        "y_pred = model.batch_get_recommend(\n",
        "        historical_ratings= test_warm_up, \n",
        "        top_k = top_k, is_remove_interacted = True, batch_size=1024*5,\n",
        "        reduce_method=\"random\", using_rapids= False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "wFw_92XSRg3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f6e8bb9-838c-4b61-a870-3ef67e8ce756"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "c8yrKhc16vyM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ebefdf25-7a57-48b2-f13d-1a8796ffc6d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          userId clusters    scores  movieId  contribute_score  rank  \\\n",
              "0              3       11  0.999995     1559          0.999996  47.0   \n",
              "1              3       11  0.999995     1568          0.999996  44.0   \n",
              "2              3       11  0.999995     1830          0.999996  35.0   \n",
              "3              3       11  0.999995     3226          0.999997  17.0   \n",
              "4              3       11  0.999995     3234          0.999996  36.0   \n",
              "...          ...      ...       ...      ...               ...   ...   \n",
              "11930599   35790       13  0.822624    96594          0.588666  50.0   \n",
              "11930624   35790       13  0.822624   102280          0.596065  34.0   \n",
              "11930695   35790       13  0.822624   118250          0.589992  39.0   \n",
              "12926587   31975        8  0.998603    95477          0.418382  39.0   \n",
              "13114087   35105        8  0.999523    95477          0.418382  45.0   \n",
              "\n",
              "         matched_score  \n",
              "0              0.99999  \n",
              "1              0.99999  \n",
              "2             0.999991  \n",
              "3             0.999992  \n",
              "4             0.999991  \n",
              "...                ...  \n",
              "11930599       0.48425  \n",
              "11930624      0.490337  \n",
              "11930695      0.485342  \n",
              "12926587      0.417798  \n",
              "13114087      0.418183  \n",
              "\n",
              "[450050 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9a06847b-8343-43f9-aa4e-c6e9ceffaf11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>clusters</th>\n",
              "      <th>scores</th>\n",
              "      <th>movieId</th>\n",
              "      <th>contribute_score</th>\n",
              "      <th>rank</th>\n",
              "      <th>matched_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>1559</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.99999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>1568</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.99999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>1830</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.999991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>3226</td>\n",
              "      <td>0.999997</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.999992</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>3234</td>\n",
              "      <td>0.999996</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.999991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11930599</th>\n",
              "      <td>35790</td>\n",
              "      <td>13</td>\n",
              "      <td>0.822624</td>\n",
              "      <td>96594</td>\n",
              "      <td>0.588666</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.48425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11930624</th>\n",
              "      <td>35790</td>\n",
              "      <td>13</td>\n",
              "      <td>0.822624</td>\n",
              "      <td>102280</td>\n",
              "      <td>0.596065</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.490337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11930695</th>\n",
              "      <td>35790</td>\n",
              "      <td>13</td>\n",
              "      <td>0.822624</td>\n",
              "      <td>118250</td>\n",
              "      <td>0.589992</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.485342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12926587</th>\n",
              "      <td>31975</td>\n",
              "      <td>8</td>\n",
              "      <td>0.998603</td>\n",
              "      <td>95477</td>\n",
              "      <td>0.418382</td>\n",
              "      <td>39.0</td>\n",
              "      <td>0.417798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13114087</th>\n",
              "      <td>35105</td>\n",
              "      <td>8</td>\n",
              "      <td>0.999523</td>\n",
              "      <td>95477</td>\n",
              "      <td>0.418382</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.418183</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>450050 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9a06847b-8343-43f9-aa4e-c6e9ceffaf11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9a06847b-8343-43f9-aa4e-c6e9ceffaf11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9a06847b-8343-43f9-aa4e-c6e9ceffaf11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "_IRQdUmSRJkA"
      },
      "outputs": [],
      "source": [
        "y_true = test_mask\n",
        "y_true[\"is_fav\"] = y_true[\"rating\"].apply(lambda x: 1 if x>2.5 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "MWcFUMZ0KoSm"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    y_true: dataframe: user_id, item_id, is_fav (1 true, 0 false)\n",
        "    y_pred: dataframe: user_id, item_id\n",
        "    return:\n",
        "    precision@k, recall@k\n",
        "    \"\"\"\n",
        "    y_pred2 = y_pred.copy()\n",
        "    y_pred2[\"is_rec\"] = 1\n",
        "    y_true2 = y_true.copy()\n",
        "\n",
        "    total1 = y_true2.merge(y_pred2, on=[userCol, itemCol], how = 'left')\n",
        "    total1[\"rec_fav\"] = total1[\"is_rec\"].fillna(0) * total1[\"is_fav\"]\n",
        "\n",
        "    # Precision\n",
        "    p = total1[\"rec_fav\"].sum() / total1[\"is_rec\"].sum()\n",
        "\n",
        "    # Recall\n",
        "    r = total1[\"rec_fav\"].sum() / total1[\"is_fav\"].sum()\n",
        "    return p, r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "D9AtAbTSOVbe"
      },
      "outputs": [],
      "source": [
        "precision, recall = evaluate_model(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "N2xZOMMPPcsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3773b13e-12ab-45a1-95bd-728074296065"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision : 0.75\n"
          ]
        }
      ],
      "source": [
        "print(\"Precision :\", precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "GdLfBLukVCbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfe4e1a1-aba6-456e-e23a-59c9f0c7f546"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.4498230732576268e-06"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIY1sccKoqF"
      },
      "source": [
        "# END HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "z8mwDaKFKp4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "cc573800-df2c-45a1-e937-9f28e77757c3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "1/0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPPnAXS9vBhG"
      },
      "outputs": [],
      "source": [
        "def evaluate_rs(y_true, y_pred, is_return_df = False):\n",
        "    \"\"\"\n",
        "    y_true: dataframe: user_id, item_id, y (rating normailised), only favorite item\n",
        "    y_pred: dataframe: user_id, item_id (just top k item)\n",
        "    return:\n",
        "    precision@k, recall@k\n",
        "    \"\"\"\n",
        "    total1 = y_true.merge(y_pred, on=[userCol, itemCol], how = 'outer', suffixes=('_t', '_p'))\n",
        "    total1['is_pt'] = total1.apply(lambda x: 0 if (np.isnan(x[\"y\"]) or np.isnan(x[\"rank\"]) ) else 1,axis=1)\n",
        "    total = total1.groupby(userCol).agg({\n",
        "        \"y\":'count',\n",
        "        \"rank\":'count',\n",
        "        \"is_pt\": 'sum'\n",
        "        })\n",
        "    total.columns = [\"true_num\", \"predict_num\", \"pred_true_num\"]\n",
        "    total[\"macro_p\"] = total[\"pred_true_num\"]/total[\"predict_num\"]\n",
        "    total[\"macro_r\"] = total[\"pred_true_num\"]/total[\"true_num\"]\n",
        "\n",
        "    total = total[total[\"predict_num\"]>0]\n",
        "\n",
        "    macro_p = total[total[\"predict_num\"]>0][\"macro_p\"].mean()\n",
        "    macro_r = total[total[\"true_num\"]>0][\"macro_r\"].mean()\n",
        "\n",
        "    micro_p = total[\"pred_true_num\"].sum()/total[\"predict_num\"].sum()\n",
        "    micro_r = total[\"pred_true_num\"].sum()/total[\"true_num\"].sum()\n",
        "\n",
        "    print(\"macro_p: \", macro_p, \"; macro_r :\", macro_r)\n",
        "    print(\"micro_p: \", micro_p, \"; micro_r :\", micro_r)\n",
        "\n",
        "    if is_return_df:\n",
        "        return (macro_p, macro_r, micro_p, micro_r), total\n",
        "\n",
        "    return macro_p, macro_r, micro_p, micro_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZKN6iNvJQFj"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "eval_map = map_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_ndcg = ndcg_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_precision = precision_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_recall = recall_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol, col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "\n",
        "print('K = %f' % top_k)\n",
        "print(\n",
        "    \"MAP:\\t%f\" % eval_map,\n",
        "      \"NDCG:\\t%f\" % eval_ndcg,\n",
        "      \"Precision@K:\\t%f\" % eval_precision,\n",
        "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i91nkjJq793s"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "eval_metrics, eval_df = evaluate_rs(y_true, y_pred, is_return_df= True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "17fHxkHoAQq6"
      ],
      "name": "v2.2_ML20M_sequence.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}