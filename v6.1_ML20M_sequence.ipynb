{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8qpAznwl3Fk"
      },
      "source": [
        "ver 6.0 \n",
        "Supervised contrastive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRXKKOy-8X1R"
      },
      "source": [
        "# Enviroment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7sPzaTKcdTo",
        "outputId": "39a2b674-d45e-4215-d77a-e461e67a9362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.17.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.2.0)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.2)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.21.6)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (2022.5.0)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.7/dist-packages (from partd>=0.3.10->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons\n",
        "# !pip install recommenders\n",
        "!pip install \"dask[dataframe]\" --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGKXb_a2GGDk"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "XS6UHXPVAQqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "import gc\n",
        "import math\n",
        "import datetime, time\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.losses import TripletSemiHardLoss \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import dask.dataframe as dd\n",
        "\n",
        "# from recommenders.datasets.python_splitters import python_random_split\n",
        "# from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
        "# from recommenders.models.cornac.cornac_utils import predict_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gv8gXemwD3UQ",
        "outputId": "48847fd8-7dfb-4db0-8d77-5cec7bb13461"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "Crhty6fiAQqu"
      },
      "outputs": [],
      "source": [
        "itemCol = 'movieId'\n",
        "userCol = 'userId'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOJJy441A0w0",
        "outputId": "25a26f18-6894-493e-feab-55c693271dbf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# DGX setup\n",
        "# fpath = \"./ml-20m\"\n",
        "\n",
        "#colab setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "fpath = \"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/ml-20m\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_DH8SxPH64nZ",
        "outputId": "5aeca6c8-bdb6-4b1c-c0c1-0147ea39cac7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                        title  \\\n",
              "0        1                    Toy Story   \n",
              "1        2                      Jumanji   \n",
              "2        3             Grumpier Old Men   \n",
              "3        4            Waiting to Exhale   \n",
              "4        5  Father of the Bride Part II   \n",
              "\n",
              "                                        genres  year  \n",
              "0  Adventure Animation Children Comedy Fantasy  1995  \n",
              "1                   Adventure Children Fantasy  1995  \n",
              "2                               Comedy Romance  1995  \n",
              "3                         Comedy Drama Romance  1995  \n",
              "4                                       Comedy  1995  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-018ba8c8-1e8c-4017-8b39-5d8abe79c642\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>year</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Adventure Animation Children Comedy Fantasy</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>Adventure Children Fantasy</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>Comedy Romance</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Comedy Drama Romance</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>1995</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-018ba8c8-1e8c-4017-8b39-5d8abe79c642')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-018ba8c8-1e8c-4017-8b39-5d8abe79c642 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-018ba8c8-1e8c-4017-8b39-5d8abe79c642');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "# Loading movie\n",
        "movies = pd.read_csv(fpath+'/movies.csv')\n",
        "movies[\"year\"]=movies[\"title\"].apply(lambda x: x[-5:-1])\n",
        "movies[\"genres\"] = movies[\"genres\"].apply(lambda x: ' ' if x == '(no genres listed)' else ' '.join(x.split('|')) )\n",
        "movies[\"title\"]= movies[\"title\"].apply(lambda x: x[0:-7])\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "fiRtTNy1ScIa"
      },
      "outputs": [],
      "source": [
        "# user-wise train-test split\n",
        "def user_wise_split(userCol, test_size=0.25):\n",
        "    df = pd.read_csv(fpath+'/ratings.csv')\n",
        "    df[\"y\"] = df[\"rating\"]/2.5-1\n",
        "    all_user = df[userCol].drop_duplicates()\n",
        "    train_user, test_user = train_test_split(all_user, test_size=test_size)\n",
        "\n",
        "    train_ratings = df[df[userCol].isin(train_user)]\n",
        "    test_ratings = df[df[userCol].isin(test_user)]\n",
        "    return train_ratings, test_ratings\n",
        "\n",
        "train, test= user_wise_split(userCol,test_size= 0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "iejmAYEB4kjy"
      },
      "outputs": [],
      "source": [
        "top_k_item = 20000\n",
        "wu_size = 200\n",
        "max_item = wu_size\n",
        "\n",
        "top_items = train.groupby(itemCol).count().sort_values(by=userCol, ascending=False).head(top_k_item).index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfY6FeqKqQ4"
      },
      "source": [
        "# Class  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "mvnW0Fd52VkU"
      },
      "outputs": [],
      "source": [
        "class TimeTrachker():\n",
        "    \"\"\"Tracking runing time\"\"\"\n",
        "    def start(self):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def check(self, des = ''):\n",
        "        try:\n",
        "            if self.check_time is None:\n",
        "                self.check_time = self.start_time\n",
        "        except:\n",
        "            self.check_time = self.start_time\n",
        "        self.end_time = time.time()\n",
        "        dur = self.end_time - self.check_time\n",
        "        print(des + \" duration: \", dur)\n",
        "\n",
        "        self.check_time = time.time()\n",
        "        return dur\n",
        "\n",
        "    def stop(self, des = ''):\n",
        "        self.end_time = time.time()\n",
        "        dur = self.end_time - self.start_time\n",
        "        print(des + \" duration: \", dur)\n",
        "        self.start_time = time.time()\n",
        "        self.check_time = None\n",
        "        return dur\n",
        "\n",
        "timer = TimeTrachker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Lb2Hx2rlWzmP"
      },
      "outputs": [],
      "source": [
        "def get_interaction_set(interaction, max_item = None, top_k_item = None):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        interaction: df[userCol, itemCol, y]: dữ liệu đầu vào\n",
        "        max_item: int: item num limit\n",
        "    Output:\n",
        "        df, itemCol: list, y: list, itemCol_str: string, userCol as index\n",
        "        list item sắp xếp theo giảm dần độ lớn rating\n",
        "    \"\"\"\n",
        "    items = interaction.groupby(itemCol).count().sort_values(by=userCol, ascending=False)\n",
        "    if top_k_item is not None:\n",
        "        top_items = items.head(top_k_item).index\n",
        "        interaction = interaction[interaction[itemCol].isin(top_items)]\n",
        "    else:\n",
        "        top_items = items.index\n",
        "\n",
        "    # Sắp xếp item theo thứ tự giảm dần rating (về sau cắt padding sẽ ưu tiên giữ lại item có rating cao)\n",
        "    rindex = interaction.groupby(userCol)[\"y\"].transform(lambda grp: grp.sort_values(ascending=False).index)\n",
        "    interaction = interaction.reindex(rindex)\n",
        "    \n",
        "    # Chuyển thành warm-up set theo từng user\n",
        "    interaction = interaction.groupby(\"userId\").agg({itemCol:list, \"y\":list})\n",
        "\n",
        "    # Giới hạn độ dài warm_up size\n",
        "    if max_item is not None:\n",
        "        interaction[itemCol] = interaction[itemCol].apply(lambda x: x[0:max_item])\n",
        "        interaction[\"y\"] = interaction[\"y\"].apply(lambda x: x[0:max_item])\n",
        "\n",
        "    return interaction, top_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "jJySyZdU4Iou"
      },
      "outputs": [],
      "source": [
        "# Bulding model\n",
        "class Efficient_Rec(tf.keras.Model):\n",
        "    def __init__(self, encoder, wu_size= 200, use_tf_function=False):\n",
        "        super().__init__()\n",
        "        self.use_tf_function = use_tf_function\n",
        "        self.encoder = encoder\n",
        "        self.wu_size = wu_size\n",
        "\n",
        "    # from v2.2: chỉ groupby, không padding\n",
        "    @staticmethod\n",
        "    def get_interaction_set(interaction, max_item = None, top_k_item = None):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            interaction: df[userCol, itemCol, y]: dữ liệu đầu vào\n",
        "            max_item: int: item num limit\n",
        "        Output:\n",
        "            df, itemCol: list, y: list, itemCol_str: string, userCol as index\n",
        "            list item sắp xếp theo giảm dần độ lớn rating\n",
        "        \"\"\"\n",
        "        items = interaction.groupby(itemCol).count().sort_values(by=userCol, ascending=False)\n",
        "        if top_k_item is not None:\n",
        "            top_items = items.head(top_k_item).index\n",
        "            interaction = interaction[interaction[itemCol].isin(top_items)]\n",
        "        else:\n",
        "            top_items = items.index\n",
        "\n",
        "        # Sắp xếp item theo thứ tự giảm dần rating (về sau cắt padding sẽ ưu tiên giữ lại item có rating cao)\n",
        "        rindex = interaction.groupby(userCol)[\"y\"].transform(lambda grp: grp.sort_values(ascending=False).index)\n",
        "        interaction = interaction.reindex(rindex)\n",
        "        \n",
        "        # Chuyển thành warm-up set theo từng user\n",
        "        interaction = interaction.groupby(\"userId\").agg({itemCol:list, \"y\":list})\n",
        "\n",
        "        # Giới hạn độ dài warm_up size\n",
        "        if max_item is not None:\n",
        "            interaction[itemCol] = interaction[itemCol].apply(lambda x: x[0:max_item])\n",
        "            interaction[\"y\"] = interaction[\"y\"].apply(lambda x: x[0:max_item])\n",
        "\n",
        "        return interaction, top_items\n",
        "\n",
        "    def _preprocess(self, inputs, padding_size = 100):\n",
        "        \"\"\"\n",
        "        Padding về wu_size và mask_size, convert list of items => string of items\n",
        "        batch_inputs: df: itemStr, y\"\"\"\n",
        "\n",
        "        def padding_list(list_item, wu_size, value=0, is_padding=True):\n",
        "            series_item1 = list_item[0:wu_size]\n",
        "            if is_padding:\n",
        "                series_item1 = series_item1+[value]*(wu_size-len(series_item1))\n",
        "            return series_item1\n",
        "\n",
        "        items_list, ratings_list = inputs\n",
        "\n",
        "        items   = items_list.apply(lambda x: ' '.join(list([str(i) for i in x])))\n",
        "        ratings =   np.stack( ratings_list.apply(lambda x: padding_list( x, padding_size  ) ) )\n",
        "\n",
        "        return items, ratings\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_top_cluster(scores, interaction_list, cluster_num=5):\n",
        "        interaction_list_ = interaction_list.copy()\n",
        "        idx = np.argsort(-scores.transpose(),axis=0)[:cluster_num]\n",
        "        interaction_list_[\"clusters\"] = [list(i) for i in idx.transpose()]\n",
        "        interaction_list_[\"scores\"] = [ list(scores[i][ind]) for i, ind in enumerate(idx.transpose()) ]\n",
        "        return interaction_list_\n",
        "\n",
        "    def minibatch_clustering(self, interaction_list, batch_size= 512):\n",
        "        chunks = [interaction_list[i:i+batch_size] for i in range(0,interaction_list.shape[0],batch_size)]\n",
        "        preds = []\n",
        "        for chunk in chunks:\n",
        "            pred = self.encoder(self._preprocess( [chunk[itemCol], chunk[\"y\"]], padding_size = wu_size )).numpy()\n",
        "            preds.append( pred )\n",
        "\n",
        "        return np.concatenate(preds)\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_explode(ratings, batch_size = 1024**2):\n",
        "        chunks = [ratings[i:i+batch_size] for i in range(0,ratings.shape[0],batch_size)]\n",
        "        explodes = []\n",
        "\n",
        "        # Todo: convert for loop to parallel\n",
        "        def chunk_process(chunk):\n",
        "            explode = chunk.explode([\"clusters\", \"scores\"])\n",
        "            explode[\"contribute_score\"] = explode[\"scores\"].astype(\"float64\")*explode[\"y\"]\n",
        "            explode = explode.groupby([\"clusters\", \"movieId\"]).agg({\n",
        "                \"contribute_score\": [\"mean\", \"count\"]\n",
        "            }).reset_index()\n",
        "            explode.columns = [\"clusters\", \"movieId\", \"mean\", \"count\"]\n",
        "\n",
        "            return explode\n",
        "\n",
        "        explodes = Parallel(n_jobs = -1, verbose = 1)(\n",
        "                    delayed(chunk_process)(chunk) for chunk in tqdm(chunks))\n",
        "        # combine results\n",
        "        gr = pd.concat(explodes, axis = 0)\n",
        "        gr[\"product\"] = gr[\"mean\"]*gr[\"count\"]\n",
        "        gr = gr.groupby([\"clusters\", \"movieId\"]).sum().reset_index()\n",
        "        gr[\"contribute_score\"] = gr[\"product\"]/gr[\"count\"]\n",
        "        gr = gr[[\"clusters\", \"movieId\", \"contribute_score\"]]\n",
        "        return gr\n",
        "\n",
        "    def get_shortlist(self, ratings, interaction_list= None, limit = 500, cluster_num = 5, batch_size=512):\n",
        "        timer.start()\n",
        "        if interaction_list is None:\n",
        "            interaction_list_, _ = self.get_interaction_set(  ratings, max_item = max_item, top_k_item = top_k_item  )\n",
        "        else:\n",
        "            interaction_list_ = interaction_list.copy()\n",
        "\n",
        "        scores = self.minibatch_clustering(interaction_list_, batch_size=batch_size)\n",
        "\n",
        "        # Limit number of cluster for each user\n",
        "        interaction_list_ = self.get_top_cluster(scores, interaction_list_, cluster_num= cluster_num)\n",
        "        timer.check(des = \"Get cluster\")\n",
        "\n",
        "        # Get shortlist for each cluster\n",
        "        ratings_ = ratings.copy().set_index(\"userId\")\n",
        "        ratings_ = ratings_[ratings_[\"y\"]>0]\n",
        "        ratings_ = ratings_.join(interaction_list_, rsuffix=\"_l\", how = \"inner\")\n",
        "        timer.check(des = \"Join interaction\")\n",
        "        ratings_ = self.chunk_explode(ratings_, batch_size= 1024*200)\n",
        "        timer.check(des = \"Chunk explode\")\n",
        "\n",
        "        ratings_[\"rank\"] = ratings_.groupby(\"clusters\")[\"contribute_score\"].rank(method='first', ascending=False)\n",
        "        ratings_ = ratings_[(ratings_[\"rank\"] <= limit)&(ratings_[\"contribute_score\"]>0)]\n",
        "        timer.check(des = \"Chunk explode\")\n",
        "\n",
        "        self.shortlist = ratings_\n",
        "\n",
        "        timer.stop(des = \"Total\")\n",
        "\n",
        "    @staticmethod\n",
        "    def left_anti_user_item_join( left, right ):\n",
        "        \"\"\"Fast left anijoin 2 dataframe by one column\"\"\"\n",
        "        wu_key = left[userCol].astype('str')+\"&\"+left[itemCol].astype('str')\n",
        "        blacklist = right[userCol].astype('str')+\"&\"+right[itemCol].astype('str')\n",
        "\n",
        "        key_diff = set(wu_key).difference(blacklist)\n",
        "        where_diff = wu_key.isin(key_diff)\n",
        "        output = left[where_diff]\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def batch_get_recommend(self, warm_up= None, historical_ratings = None, top_k = 10, is_remove_interacted = True, \n",
        "        batch_size=1024, reduce_method=\"random\", using_rapids= False, cluster_num= 5):\n",
        "        \"\"\"\n",
        "        reduce_method: str, 'random' or 'mean'\n",
        "        \"\"\"\n",
        "        print(\"historical_ratings shape \", historical_ratings.shape)\n",
        "        timer.start()\n",
        "        if warm_up is None:\n",
        "            warm_up, _ = self.get_interaction_set( \n",
        "                         historical_ratings\n",
        "                        , max_item = max_item\n",
        "                        , top_k_item = top_k_item )\n",
        "\n",
        "        scores = self.minibatch_clustering(warm_up, batch_size=512)\n",
        "        wu = self.get_top_cluster( scores, warm_up, cluster_num= cluster_num)\n",
        "\n",
        "        wu = wu.explode([\"clusters\", \"scores\"]).reset_index()[[userCol, \"clusters\", \"scores\"]]\n",
        "        timer.check(des = \"Get cluster for user\")\n",
        "        print(\"wu shape \", wu.shape)\n",
        "        \n",
        "        user_num = wu[userCol].drop_duplicates().shape[0]\n",
        "        print(\"user_num \", user_num)\n",
        "\n",
        "        # cudf.from_pandas\n",
        "        if using_rapids:\n",
        "            wu = dd.from_pandas(wu)\n",
        "            historical_ratings = dd.from_pandas(historical_ratings.copy())\n",
        "\n",
        "        chunks = [wu[wu[userCol].isin(range(i,i+batch_size))] \n",
        "                  for i in range(0,user_num,batch_size)]\n",
        "\n",
        "        his_chunks = [historical_ratings[historical_ratings[userCol].isin(range(i,i+batch_size))] \n",
        "                        for i in range(0,user_num,batch_size)]\n",
        "       \n",
        "        shortlist = self.shortlist\n",
        "\n",
        "        def batch_join_process(chunk, his_chunk):\n",
        "            timer2 = TimeTrachker()\n",
        "            timer2.start()\n",
        "\n",
        "            wu = chunk.merge(shortlist, on=\"clusters\", how='inner')\n",
        "            print('''wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape: ''', wu.shape)\n",
        "            wu[\"matched_score\"] = wu[\"scores\"]*wu[\"contribute_score\"]\n",
        "\n",
        "            if reduce_method==\"mean\":\n",
        "                wu = wu.groupby([userCol, itemCol]).agg({\"matched_score\":'mean'}).reset_index()\n",
        "            \n",
        "            if reduce_method==\"random\":\n",
        "                # using drop_duplicates for boost speed, may reduce accuracy.\n",
        "                wu = wu.drop_duplicates(subset=[\"userId\", \"movieId\"])\n",
        "\n",
        "            print('''after reduce wu shape: ''', wu.shape)\n",
        "            timer2.check(des = \"reduce\")\n",
        "\n",
        "            if is_remove_interacted:\n",
        "                wu = self.left_anti_user_item_join( wu, historical_ratings )\n",
        "\n",
        "            print('''after remove interacted wu shape: ''', wu.shape)\n",
        "            timer2.check(des = \"remove interacted item\")\n",
        "\n",
        "            wu[\"rank\"] = wu.groupby(userCol)[\"matched_score\"].rank(method='first', ascending=False)\n",
        "            wu = wu[wu[\"rank\"]<= top_k]\n",
        "\n",
        "            timer2.stop(des = \"all chunk processing time\")\n",
        "\n",
        "            return wu \n",
        "        \n",
        "        timer.check(des = \"Prepare to join\")\n",
        "        wus = Parallel(n_jobs = -1, backend= 'threading', verbose = 1)(\n",
        "                    delayed(batch_join_process)(chunk, his_chunk) for chunk, his_chunk in tqdm(zip(chunks, his_chunks)))\n",
        "        \n",
        "        gc.collect()\n",
        "\n",
        "        timer.check(des = \"Join\")\n",
        "\n",
        "        output = pd.concat(wus, axis=0)\n",
        "\n",
        "        timer.stop(des = \"Total\")\n",
        "        return output\n",
        "\n",
        "    def release_cache(self):\n",
        "        self.interaction_list = None \n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbp1tH7yUeI6"
      },
      "source": [
        "# Xây dựng encoder model\n",
        "Encoder =  interaction embedding + user feature embedding<br> \n",
        "interaction embedding = sum( interaction embedding các item i)<br> \n",
        "interaction embedding item i = rating x (embedding id sản phẩm + embedding item feature)<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxNyuo9-WJJG",
        "outputId": "8a57e6f6-4fd9-42cc-aece-ba08ace35eed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 432 ms, sys: 64.9 ms, total: 497 ms\n",
            "Wall time: 2.09 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Vectorize (encode + padding) item list\n",
        "max_vocab_size = len(top_items) # nếu số item có <= top_k_item => lấy số lượng item max\n",
        "items_str = ' '.join([str(i) for i in top_items])\n",
        "itemStr = itemCol+\"_str\"\n",
        "\n",
        "vectorizer = layers.TextVectorization( max_tokens= top_k_item, split='whitespace', output_sequence_length= wu_size, name = 'vectorizer')\n",
        "vectorizer.adapt( [items_str] ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "1U7EQG6zWpi9"
      },
      "outputs": [],
      "source": [
        "class Broadcasting_Multiply(tf.keras.layers.Layer):\n",
        "    \"\"\"Nhân 2 layers khác shape với nhau, trong đó:\n",
        "    inputs=[layer1, layer2]\n",
        "    layer1.shape = (None, n_item, n_feature)\n",
        "    layer2.shape = (None, n_item)\n",
        "    (Chú ý đúng thứ tự)\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, y = inputs\n",
        "        deno = tf.expand_dims(tf.cast(tf.math.count_nonzero(y, axis=1), tf.float32), -1)\n",
        "        #we add the extra dimension:\n",
        "        y = K.expand_dims(y, axis=-1)\n",
        "        #we replicate the elements\n",
        "        y = K.repeat_elements(y, rep=x.shape[2], axis=-1)\n",
        "\n",
        "        return x * y, deno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "--fbIsGLXjPD"
      },
      "outputs": [],
      "source": [
        "# Xây dựng mạng\n",
        "embedding_size = 173\n",
        "reps_size = 132\n",
        "preference_vector_size = 43\n",
        "\n",
        "@tf.function\n",
        "def avg_layer(z):\n",
        "    t = K.sum(z[0], axis=1)/z[1]\n",
        "    t = tf.clip_by_value( t, -1, 1 )\n",
        "    t = tf.where(tf.math.is_nan(t), tf.zeros_like(t), t)\n",
        "    return t\n",
        "\n",
        "\n",
        "def interaction_embedding():\n",
        "\n",
        "    input_wi = layers.Input(shape=(1,), name='input_wi')\n",
        "    wi = vectorizer(input_wi)\n",
        "    wi = layers.Embedding(input_dim= max_vocab_size, output_dim= embedding_size, mask_zero= True, name='ei')(wi)\n",
        "    # wi = layers.Dense(embedding_size, activation='sigmoid', use_bias = False, name='di')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='relu', use_bias = False, name='di1')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='relu', use_bias = False, name='di2')(wi)\n",
        "    # wi = layers.Dense(embedding_size, activation='sigmoid', use_bias = False, name='di3')(wi)\n",
        "\n",
        "    wr = layers.Input(shape=(wu_size,), name='warm_up_ratings')\n",
        "\n",
        "    ireps = Broadcasting_Multiply(name='mul')([wi, wr])\n",
        "    uprofile = layers.Lambda(lambda z: avg_layer(z) )(ireps)\n",
        "\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du1')(uprofile)\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du2')(uprofile)\n",
        "    # uprofile = layers.Dense( reps_size, activation='relu', name='du3')(uprofile)\n",
        "    # uprofile = layers.BatchNormalization(name='norm')(uprofile)\n",
        "    uprofile = layers.LayerNormalization(name='norm')(uprofile)\n",
        "    # uprofile = layers.Dense( reps_size, activation='relu', name='du4')(uprofile)\n",
        "    uprofile = layers.Dense(preference_vector_size, activation='sigmoid', name='clustering')(uprofile)\n",
        "    \n",
        "    \n",
        "    model = tf.keras.Model(inputs= [input_wi, wr], outputs=[uprofile])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "a7EW-lg9Cfi5"
      },
      "outputs": [],
      "source": [
        "# # Example of layer interaction embedding step by step\n",
        "# input_wi = [\"15 25 65 20 84\",  # 5 items\n",
        "#             \"51 54 45 21 24 83 81 76 74 75 72 48 29 38\",# 14 items\n",
        "#             \" \", # 0 item\n",
        "#             ] \n",
        "\n",
        "# tvectorizer = layers.TextVectorization( max_tokens= 17, split='whitespace', output_sequence_length= 10)\n",
        "# tvectorizer.adapt( input_wi ) \n",
        "\n",
        "# wi = tvectorizer(input_wi)\n",
        "# print(\"afer TextVectorization layer \\n\",wi)\n",
        "# wi = layers.Embedding(input_dim= 17, output_dim= 4, mask_zero= True, name='ei')(wi)\n",
        "# print(\"afer Embedding layer \\n\",wi)\n",
        "# wi = layers.Dense(3, activation='sigmoid',  use_bias = False, name='di')(wi)\n",
        "\n",
        "# wr = np.array([[0.5, 0.1, -0.5, 1, 0.25, 0, 0, 0, 0, 0], [0.25, 0.15, 0.5, 1, 0.25, 0.5, 0.1, -0.9, 0.4, -0.3], [0,0,0,0,0,0,0,0,0,0]])\n",
        "\n",
        "# ireps = Broadcasting_Multiply(name='mul')([wi, wr])\n",
        "# print(\"afer Multiply layer \\n\",ireps)\n",
        "# uprofile = layers.Lambda(lambda z: avg_layer(z) )(ireps)\n",
        "# print(\"afer Average layer \\n\",uprofile)\n",
        "\n",
        "# uprofile = layers.Dense( reps_size, activation='relu', name='du2')(uprofile)\n",
        "# uprofile = layers.LayerNormalization(name='norm')(uprofile)\n",
        "# uprofile = layers.Dense(5, activation='sigmoid', name='clustering')(uprofile)\n",
        "# print(\"afer Sigmoid layer \\n\",uprofile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "cJMxOoxzXvr_"
      },
      "outputs": [],
      "source": [
        "# Kiểm tra tham số\n",
        "# interaction_embedding().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "PuAM8w01Xy93"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model( interaction_embedding() ,show_shapes=True, show_dtype=True, show_layer_names=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BISfMUNM37ug"
      },
      "source": [
        "# Evaluate model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "83VIKSPGNrN6"
      },
      "outputs": [],
      "source": [
        "def model_evaluate(model, movies, df):\n",
        "    dfu, ttop_items = get_interaction_set( df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    group_scores = model.encoder(model._preprocess( [dfu[itemCol], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "\n",
        "    print(\"SAMPLE INTERACTION EMBEDDING\")\n",
        "    print( np.max(group_scores), np.mean(group_scores), np.min(group_scores) )\n",
        "    print( group_scores[0:3] )\n",
        "\n",
        "    print(\"FEATURE PLOT\")\n",
        "    feature_plot( movies, df, group_scores)\n",
        "    \n",
        "    print(\"CLUSTER CHECKING\")\n",
        "    check_cluster(group_scores)\n",
        "    \n",
        "    print(\"SPECTROGRAM PLOT\")\n",
        "    plot_spectrogram(group_scores)\n",
        "\n",
        "def get_label(movies, df, is_encode = False):\n",
        "    movies[\"genres_list\"] = movies[\"genres\"].apply(lambda x: x.split(' '))\n",
        "    movie_genres = movies.explode(\"genres_list\")\n",
        "    gr = df.merge(movie_genres, on=\"movieId\").groupby([\"userId\", \"genres_list\"])[\"movieId\"].count().reset_index()\n",
        "    gr[\"rank\"] = gr.groupby(\"userId\")[\"movieId\"].rank(method='first', ascending=False)\n",
        "\n",
        "    labels = gr[gr[\"rank\"] ==1].set_index(\"userId\")\n",
        "    # labels[\"pred_max_ind\"] = np.argmax(group_scores, axis=1)\n",
        "\n",
        "    if is_encode:\n",
        "        label_enc = LabelEncoder()\n",
        "        labels[\"label\"] = label_enc.fit_transform(labels[\"genres_list\"])\n",
        "\n",
        "    return labels\n",
        "\n",
        "def feature_plot( movies, df, group_scores ):\n",
        "    tlabels = get_label(movies, df)\n",
        "\n",
        "    tsne = PCA(n_components=2, random_state=123)\n",
        "    # tsne = TSNE(n_components=2, random_state=123)\n",
        "    z = tsne.fit_transform(group_scores) \n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y\"] = tlabels[\"genres_list\"]\n",
        "    df[\"comp-1\"] = z[:,0]\n",
        "    df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (8,8)\n",
        "    sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                    palette=\"Paired\" ,#sns.color_palette(\"hls\", 3),\n",
        "                    data=df)#.set(title=\"Iris data T-SNE projection\") \n",
        "    plt.show()\n",
        "\n",
        "def check_cluster(group_scores):\n",
        "    # Kiểm tra số user trong mỗi cụm có bị vón cục\n",
        "    ugs= np.argmax(group_scores, axis=1)\n",
        "    for i in range(50):\n",
        "        print(i,': ', np.sum(ugs==i) )\n",
        "\n",
        "def plot_spectrogram(group_scores):\n",
        "    # Sort theo user_group + draw sigmoid/softmax layer\n",
        "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "    k =100\n",
        "    a = group_scores\n",
        "    ind = np.argmax(group_scores, axis=1)\n",
        "    plt.imshow( a[np.argsort(ind)][0:k] )\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "_cs4Ci70vrkA"
      },
      "outputs": [],
      "source": [
        "def model_plot(model, movies, df):\n",
        "    dfu, ttop_items = get_interaction_set( df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    group_scores = model.encoder(model._preprocess( [dfu[itemCol], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "    print(\"FEATURE PLOT\")\n",
        "    feature_plot( movies, df, group_scores)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfUOMI8subTw"
      },
      "source": [
        "# Warm start user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQtBh9xFunkU",
        "outputId": "d04a06f6-17cd-4cf3-b628-cda248ea9975"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(37194, 4)\n",
            "CPU times: user 2.33 ms, sys: 0 ns, total: 2.33 ms\n",
            "Wall time: 7.9 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "u_train_from = 0\n",
        "u_train_to = u_train_from + 130000\n",
        "u_test = u_train_to + 5000\n",
        "\n",
        "def get_labeled_data(df):\n",
        "    interact_df, _ = get_interaction_set( \n",
        "                     df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    labels = get_label( movies, df, is_encode = True)\n",
        "    interact_df[\"label\"] = labels[\"label\"]\n",
        "    return interact_df[[\"movieId\",\"y\",\"label\"]]\n",
        "try:\n",
        "    train_warm\n",
        "except:\n",
        "    # if exists, do not rerun\n",
        "    train_warm =  get_labeled_data( train[(train[userCol]>u_train_from)&(train[userCol]<u_train_to)] )\n",
        "    train_warm[\"rating_num\"] = train_warm.apply(lambda x: len(x[\"y\"]), axis=1)\n",
        "    # pretrain with warm start user\n",
        "    train_warm = train_warm[train_warm[\"rating_num\"]>=100]\n",
        "\n",
        "print( train_warm.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "aGY_dv9cV3Br"
      },
      "outputs": [],
      "source": [
        "# x = train[[\"userId\", \"rating\"]].groupby(\"userId\").count()\n",
        "# x[\"rating_num_clip\"] = x[\"rating\"].clip(0, 700).apply(lambda x: int(x/20)*20)\n",
        "# x.groupby(\"rating_num_clip\").count().plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "uFZiUT4FXHqn"
      },
      "outputs": [],
      "source": [
        "# x.groupby(\"rating_num_clip\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE0hPo7UFNkV",
        "outputId": "fb9c5699-1087-4444-b745-d6242ecb05dc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "333"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wO4EX1_Z-h3"
      },
      "source": [
        "# supervised constrastive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "hQ-pwUZafD__"
      },
      "outputs": [],
      "source": [
        "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "TbltflgfUmXf"
      },
      "outputs": [],
      "source": [
        "# Thực hiện training\n",
        "def _supervised_constrastive_train_step(self, inputs):\n",
        "    items_pd, ratings_pd, labels = inputs[\"movieId\"], inputs[\"y\"], inputs[\"label\"]\n",
        "    items, ratings = self._preprocess((items_pd, ratings_pd), wu_size)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Interaction embedding\n",
        "        vec = self.encoder([items, ratings])\n",
        "\n",
        "        average_loss = self.loss(labels, vec)\n",
        "\n",
        "    # Apply an optimization step\n",
        "    variables = self.trainable_variables \n",
        "    gradients = tape.gradient(average_loss, variables)\n",
        "    \n",
        "    # Gradient clipping\n",
        "    # gradients = [None if gradient is None else tf.clip_by_value(gradient, -0.1, 0.1)\n",
        "    #              for gradient in gradients]\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "\n",
        "Efficient_Rec._supervised_constrastive_train_step = _supervised_constrastive_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "qSr05iptaPha"
      },
      "outputs": [],
      "source": [
        "# Thực hiện minibatch training\n",
        "def _spv_constrastive_train_minibatch_step(self, inputs, batch_size):\n",
        "    df = inputs.copy()\n",
        "    chunks = [df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]\n",
        "    losses = []\n",
        "    for chunk in chunks:\n",
        "        loss = self._supervised_constrastive_train_step(chunk)\n",
        "        losses.append(loss[\"batch_loss\"].numpy())\n",
        "        print(loss)\n",
        "        gc.collect()\n",
        "    return np.mean(losses)\n",
        "\n",
        "Efficient_Rec._spv_constrastive_train_minibatch_step = _spv_constrastive_train_minibatch_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "uBCoJlJMdB7y"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model = Efficient_Rec( encoder = interaction_embedding(), \n",
        "                      wu_size = wu_size,\n",
        "                      use_tf_function=False)\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate = 0.001),\n",
        "    loss= TripletSemiHardLoss() # SupervisedContrastiveLoss(temperature = 0.05),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It6_5yszGfK7"
      },
      "outputs": [],
      "source": [
        "# Load trained model\n",
        "latest = tf.train.latest_checkpoint(\"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/\")\n",
        "model.encoder.load_weights(latest)\n",
        "test_set = train[(train[userCol]>10000)&(train[userCol]<12500)]\n",
        "model_plot(model, movies, test_set )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "VoepslyXhaQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fdb3596-3499-402c-b002-529c7c01e2a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
            "Wall time: 8.58 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Train new model\n",
        "# epochs= 6\n",
        "# test_set = train[(train[userCol]>10000)&(train[userCol]<12500)]\n",
        "# model_plot(model, movies, test_set )\n",
        "# for n in range(epochs):\n",
        "#   print(n, \"/\", epochs, \": \", model._spv_constrastive_train_minibatch_step(train_warm.sample(frac=1.), batch_size=512))\n",
        "#   model_plot(model, movies, test_set )\n",
        "#   gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "M9_P8ZBsFGJb"
      },
      "outputs": [],
      "source": [
        "# model.encoder.save_weights(\"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/encoder_v6\",save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "ZZUCY20TSjFk"
      },
      "outputs": [],
      "source": [
        "# model_evaluate(model, movies, \n",
        "#                warm_up_mask[(warm_up_mask[userCol]>u_train_to)&(warm_up_mask[userCol]<=u_test)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgfpZRoGF1KK"
      },
      "source": [
        "# Pick item pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQtrddWcEaoY",
        "outputId": "16fdef7c-e808-4750-9261-24003dfc8b9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get cluster duration:  33.33707141876221\n",
            "Join interaction duration:  2.4312074184417725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/34 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "100%|██████████| 34/34 [00:30<00:00,  1.12it/s]\n",
            "[Parallel(n_jobs=-1)]: Done  34 out of  34 | elapsed:   32.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk explode duration:  33.43799114227295\n",
            "Chunk explode duration:  0.1078341007232666\n",
            "Total duration:  69.31924796104431\n",
            "CPU times: user 1min 5s, sys: 4.22 s, total: 1min 9s\n",
            "Wall time: 1min 10s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "model.get_shortlist( \n",
        "    ratings = train[train[userCol].isin(train_warm.index)],\n",
        "    interaction_list = train_warm,\n",
        "    limit = 50, \n",
        "    cluster_num = 5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "0EvrD1tOVkXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714940af-befc-4bf0-86d2-7995a63cd0c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1715"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 234,
      "metadata": {
        "id": "pO4O1LwBXrOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "8a4709d8-f2ce-4569-d474-7245f560113e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        clusters  movieId  contribute_score  rank\n",
              "1505           0     1568          0.999918  30.0\n",
              "1727           0     1830          0.999906  42.0\n",
              "8434           0    26080          0.999934  11.0\n",
              "8752           0    26610          0.999922  18.0\n",
              "8996           0    27236          0.999937   8.0\n",
              "...          ...      ...               ...   ...\n",
              "356794        42    95839          0.999120   8.0\n",
              "356964        42   100277          0.998637  39.0\n",
              "357020        42   101971          0.999030  12.0\n",
              "357051        42   102991          0.998637  40.0\n",
              "357397        42   113612          0.998708  28.0\n",
              "\n",
              "[2100 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0c19fd1c-d6f3-499c-aae3-6a57801e650f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clusters</th>\n",
              "      <th>movieId</th>\n",
              "      <th>contribute_score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1505</th>\n",
              "      <td>0</td>\n",
              "      <td>1568</td>\n",
              "      <td>0.999918</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1727</th>\n",
              "      <td>0</td>\n",
              "      <td>1830</td>\n",
              "      <td>0.999906</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8434</th>\n",
              "      <td>0</td>\n",
              "      <td>26080</td>\n",
              "      <td>0.999934</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8752</th>\n",
              "      <td>0</td>\n",
              "      <td>26610</td>\n",
              "      <td>0.999922</td>\n",
              "      <td>18.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8996</th>\n",
              "      <td>0</td>\n",
              "      <td>27236</td>\n",
              "      <td>0.999937</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356794</th>\n",
              "      <td>42</td>\n",
              "      <td>95839</td>\n",
              "      <td>0.999120</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356964</th>\n",
              "      <td>42</td>\n",
              "      <td>100277</td>\n",
              "      <td>0.998637</td>\n",
              "      <td>39.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357020</th>\n",
              "      <td>42</td>\n",
              "      <td>101971</td>\n",
              "      <td>0.999030</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357051</th>\n",
              "      <td>42</td>\n",
              "      <td>102991</td>\n",
              "      <td>0.998637</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357397</th>\n",
              "      <td>42</td>\n",
              "      <td>113612</td>\n",
              "      <td>0.998708</td>\n",
              "      <td>28.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2100 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c19fd1c-d6f3-499c-aae3-6a57801e650f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0c19fd1c-d6f3-499c-aae3-6a57801e650f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0c19fd1c-d6f3-499c-aae3-6a57801e650f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 234
        }
      ],
      "source": [
        "model.shortlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {
        "id": "cwQnzbWCxd9u"
      },
      "outputs": [],
      "source": [
        "test_warm_up, test_mask = train_test_split(test, test_size= 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "a1MUU9bdHQAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7b30529-d422-41ce-d3f7-f733b598f6fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "historical_ratings shape  (2485776, 5)\n",
            "Get cluster for user duration:  46.58424186706543\n",
            "wu shape  (276992, 3)\n",
            "user_num  34624\n",
            "Prepare to join duration:  0.36055755615234375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (1024750, 6)\n",
            "(1026300, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after reduce wu shape: after reduce wu shape:  (752757, 7)\n",
            "reduce duration:  4.616408586502075\n",
            " (753332, 7)\n",
            "reduce duration:  4.622743129730225\n",
            "after remove interacted wu shape: after remove interacted wu shape:  (752802, 7)\n",
            "remove interacted item duration:  14.69712519645691\n",
            " (752146, 7)\n",
            "remove interacted item duration:  14.706331253051758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "4it [00:21,  5.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all chunk processing time duration:  21.567527294158936\n",
            "all chunk processing time duration:  21.6275851726532\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (1013200, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (1031350, 6)\n",
            "after reduce wu shape: after reduce wu shape:  (754708, 7)\n",
            "reduce duration:  4.60628080368042\n",
            " (740568, 7)\n",
            "reduce duration:  4.673604249954224\n",
            "after remove interacted wu shape: after remove interacted wu shape:  (754185, 7)\n",
            "remove interacted item duration:  14.363788843154907\n",
            " (739984, 7)\n",
            "remove interacted item duration:  14.36606502532959\n",
            "all chunk processing time duration:  21.253352642059326all chunk processing time duration:  21.351956367492676\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   42.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Join duration:  43.55996108055115\n",
            "Total duration:  90.57707929611206\n",
            "CPU times: user 1min 48s, sys: 2.61 s, total: 1min 51s\n",
            "Wall time: 1min 30s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "# interaction_list = train_warm[train_warm.index<=3000]\n",
        "top_k = 50\n",
        "is_remove_interacted = True\n",
        "\n",
        "y_pred = model.batch_get_recommend(\n",
        "        historical_ratings= test_warm_up, \n",
        "        top_k = top_k, is_remove_interacted = True, batch_size= 1024*10,\n",
        "        reduce_method=\"random\", using_rapids= False, cluster_num= 8\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "id": "wFw_92XSRg3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5657a62a-f388-4a03-998d-78ebb2a2c396"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 237
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "c8yrKhc16vyM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "e143e3ee-e3b8-44dd-f8ab-1135f0db0db2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         userId clusters    scores  movieId  contribute_score  rank  \\\n",
              "0             7        4  0.999891     1559          0.999917  44.0   \n",
              "1             7        4  0.999891     6098          0.999953  26.0   \n",
              "2             7        4  0.999891     8427          0.999945  28.0   \n",
              "3             7        4  0.999891    26232          0.999994   5.0   \n",
              "4             7        4  0.999891    27675          0.999909  47.0   \n",
              "...         ...      ...       ...      ...               ...   ...   \n",
              "1026475   33251       34   0.98294     3477          0.994231  45.0   \n",
              "1026477   33251       34   0.98294     3910          0.993813  49.0   \n",
              "1026484   33251       34   0.98294     5994          0.994231  46.0   \n",
              "1026485   33251       34   0.98294     7132          0.994231  47.0   \n",
              "1026489   33251       34   0.98294     8865          0.994231  48.0   \n",
              "\n",
              "        matched_score  \n",
              "0            0.999808  \n",
              "1            0.999844  \n",
              "2            0.999836  \n",
              "3            0.999885  \n",
              "4              0.9998  \n",
              "...               ...  \n",
              "1026475      0.977269  \n",
              "1026477      0.976859  \n",
              "1026484      0.977269  \n",
              "1026485      0.977269  \n",
              "1026489      0.977269  \n",
              "\n",
              "[512900 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-778dce1e-5021-43aa-843c-5f4d736c1cf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>clusters</th>\n",
              "      <th>scores</th>\n",
              "      <th>movieId</th>\n",
              "      <th>contribute_score</th>\n",
              "      <th>rank</th>\n",
              "      <th>matched_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.999891</td>\n",
              "      <td>1559</td>\n",
              "      <td>0.999917</td>\n",
              "      <td>44.0</td>\n",
              "      <td>0.999808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.999891</td>\n",
              "      <td>6098</td>\n",
              "      <td>0.999953</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0.999844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.999891</td>\n",
              "      <td>8427</td>\n",
              "      <td>0.999945</td>\n",
              "      <td>28.0</td>\n",
              "      <td>0.999836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.999891</td>\n",
              "      <td>26232</td>\n",
              "      <td>0.999994</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.999885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>0.999891</td>\n",
              "      <td>27675</td>\n",
              "      <td>0.999909</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.9998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026475</th>\n",
              "      <td>33251</td>\n",
              "      <td>34</td>\n",
              "      <td>0.98294</td>\n",
              "      <td>3477</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.977269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026477</th>\n",
              "      <td>33251</td>\n",
              "      <td>34</td>\n",
              "      <td>0.98294</td>\n",
              "      <td>3910</td>\n",
              "      <td>0.993813</td>\n",
              "      <td>49.0</td>\n",
              "      <td>0.976859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026484</th>\n",
              "      <td>33251</td>\n",
              "      <td>34</td>\n",
              "      <td>0.98294</td>\n",
              "      <td>5994</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.977269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026485</th>\n",
              "      <td>33251</td>\n",
              "      <td>34</td>\n",
              "      <td>0.98294</td>\n",
              "      <td>7132</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>47.0</td>\n",
              "      <td>0.977269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1026489</th>\n",
              "      <td>33251</td>\n",
              "      <td>34</td>\n",
              "      <td>0.98294</td>\n",
              "      <td>8865</td>\n",
              "      <td>0.994231</td>\n",
              "      <td>48.0</td>\n",
              "      <td>0.977269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>512900 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-778dce1e-5021-43aa-843c-5f4d736c1cf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-778dce1e-5021-43aa-843c-5f4d736c1cf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-778dce1e-5021-43aa-843c-5f4d736c1cf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 238
        }
      ],
      "source": [
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "_IRQdUmSRJkA"
      },
      "outputs": [],
      "source": [
        "y_true = test_mask\n",
        "y_true[\"is_fav\"] = y_true[\"rating\"].apply(lambda x: 1 if x>2.5 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "id": "MWcFUMZ0KoSm"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    y_true: dataframe: user_id, item_id, is_fav (1 true, 0 false)\n",
        "    y_pred: dataframe: user_id, item_id\n",
        "    return:\n",
        "    precision@k, recall@k\n",
        "    \"\"\"\n",
        "    y_pred2 = y_pred.copy()\n",
        "    y_pred2[\"is_rec\"] = 1\n",
        "    y_true2 = y_true.copy()\n",
        "\n",
        "    total1 = y_true2.merge(y_pred2, on=[userCol, itemCol], how = 'left')\n",
        "    total1[\"rec_fav\"] = total1[\"is_rec\"].fillna(0) * total1[\"is_fav\"]\n",
        "\n",
        "    # Precision\n",
        "    p = total1[\"rec_fav\"].sum() / total1[\"is_rec\"].sum()\n",
        "\n",
        "    # Recall\n",
        "    r = total1[\"rec_fav\"].sum() / total1[\"is_fav\"].sum()\n",
        "\n",
        "    print(\"Total matched groundtrust/prediction: \", total1[\"is_rec\"].sum())\n",
        "    print(\"Total label: \", total1[\"is_fav\"].sum() )\n",
        "    return p, r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 241,
      "metadata": {
        "id": "D9AtAbTSOVbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59721ef7-0016-4573-ef06-2873ee368ad1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total matched groundtrust/prediction:  90.0\n",
            "Total label:  2050304\n"
          ]
        }
      ],
      "source": [
        "precision, recall = evaluate_model(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "N2xZOMMPPcsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583157ce-32a9-41af-bbbc-3bf3e9a85b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision : 0.4888888888888889\n"
          ]
        }
      ],
      "source": [
        "print(\"Precision :\", precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "metadata": {
        "id": "GdLfBLukVCbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aacdcbf-1f00-4403-8731-bbcb0c29b611"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1460232238731428e-05"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ],
      "source": [
        "recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIY1sccKoqF"
      },
      "source": [
        "# END HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "metadata": {
        "id": "z8mwDaKFKp4U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "59472206-282f-4364-a08d-97c1d7c2d4eb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ZeroDivisionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-244-9e1622b385b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
          ]
        }
      ],
      "source": [
        "1/0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPPnAXS9vBhG"
      },
      "outputs": [],
      "source": [
        "def evaluate_rs(y_true, y_pred, is_return_df = False):\n",
        "    \"\"\"\n",
        "    y_true: dataframe: user_id, item_id, y (rating normailised), only favorite item\n",
        "    y_pred: dataframe: user_id, item_id (just top k item)\n",
        "    return:\n",
        "    precision@k, recall@k\n",
        "    \"\"\"\n",
        "    total1 = y_true.merge(y_pred, on=[userCol, itemCol], how = 'outer', suffixes=('_t', '_p'))\n",
        "    total1['is_pt'] = total1.apply(lambda x: 0 if (np.isnan(x[\"y\"]) or np.isnan(x[\"rank\"]) ) else 1,axis=1)\n",
        "    total = total1.groupby(userCol).agg({\n",
        "        \"y\":'count',\n",
        "        \"rank\":'count',\n",
        "        \"is_pt\": 'sum'\n",
        "        })\n",
        "    total.columns = [\"true_num\", \"predict_num\", \"pred_true_num\"]\n",
        "    total[\"macro_p\"] = total[\"pred_true_num\"]/total[\"predict_num\"]\n",
        "    total[\"macro_r\"] = total[\"pred_true_num\"]/total[\"true_num\"]\n",
        "\n",
        "    total = total[total[\"predict_num\"]>0]\n",
        "\n",
        "    macro_p = total[total[\"predict_num\"]>0][\"macro_p\"].mean()\n",
        "    macro_r = total[total[\"true_num\"]>0][\"macro_r\"].mean()\n",
        "\n",
        "    micro_p = total[\"pred_true_num\"].sum()/total[\"predict_num\"].sum()\n",
        "    micro_r = total[\"pred_true_num\"].sum()/total[\"true_num\"].sum()\n",
        "\n",
        "    print(\"macro_p: \", macro_p, \"; macro_r :\", macro_r)\n",
        "    print(\"micro_p: \", micro_p, \"; micro_r :\", micro_r)\n",
        "\n",
        "    if is_return_df:\n",
        "        return (macro_p, macro_r, micro_p, micro_r), total\n",
        "\n",
        "    return macro_p, macro_r, micro_p, micro_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZKN6iNvJQFj"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "eval_map = map_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_ndcg = ndcg_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_precision = precision_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_recall = recall_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol, col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "\n",
        "print('K = %f' % top_k)\n",
        "print(\n",
        "    \"MAP:\\t%f\" % eval_map,\n",
        "      \"NDCG:\\t%f\" % eval_ndcg,\n",
        "      \"Precision@K:\\t%f\" % eval_precision,\n",
        "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i91nkjJq793s"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "eval_metrics, eval_df = evaluate_rs(y_true, y_pred, is_return_df= True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "17fHxkHoAQq6"
      ],
      "name": "v2.2_ML20M_sequence.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}