{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanvu0996/TF_cert_training/blob/main/v6.2_ML20M_sequence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8qpAznwl3Fk"
      },
      "source": [
        "ver 6.0 \n",
        "Supervised contrastive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRXKKOy-8X1R"
      },
      "source": [
        "# Enviroment setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7sPzaTKcdTo",
        "outputId": "5f2fa8b2-61c0-411c-8adf-e9efaf5f095b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.17.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-addons) (3.0.9)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.17.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.7/dist-packages (2.12.0)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (0.11.2)\n",
            "Requirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]) (1.21.6)\n",
            "Collecting fsspec>=0.6.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.0->dask[dataframe]) (2022.1)\n",
            "Collecting locket\n",
            "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.0->dask[dataframe]) (1.15.0)\n",
            "Installing collected packages: locket, partd, fsspec\n",
            "Successfully installed fsspec-2022.5.0 locket-1.0.0 partd-1.2.0\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 10.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 8.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 1.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 92 kB 13.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 237 kB 73.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 62.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 352 kB 73.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 51.2 MB/s \n",
            "\u001b[?25h  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-addons\n",
        "# !pip install recommenders\n",
        "!pip install \"dask[dataframe]\" --upgrade\n",
        "!pip install -q -U \"tensorflow-text==2.8.*\"\n",
        "!pip install -q tf-models-official==2.7.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGKXb_a2GGDk"
      },
      "source": [
        "# Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XS6UHXPVAQqs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "import gc\n",
        "import math\n",
        "import datetime, time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.losses import TripletSemiHardLoss \n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from tqdm import tqdm\n",
        "import dask.dataframe as dd\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "# from recommenders.datasets.python_splitters import python_random_split\n",
        "# from recommenders.evaluation.python_evaluation import map_at_k, ndcg_at_k, precision_at_k, recall_at_k\n",
        "# from recommenders.models.cornac.cornac_utils import predict_ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Gv8gXemwD3UQ",
        "outputId": "ae724a51-abf0-4d89-b14a-9c7a3f3e026f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "ncVNKgcAeN9-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Movies"
      ],
      "metadata": {
        "id": "1iqOi1wYePj2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Crhty6fiAQqu"
      },
      "outputs": [],
      "source": [
        "itemCol = 'movieId'\n",
        "userCol = 'userId'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOJJy441A0w0",
        "outputId": "613da8f3-12ab-405f-d3de-627ab952c51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# DGX setup\n",
        "# fpath = \"./ml-20m\"\n",
        "\n",
        "#colab setup\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "fpath = \"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/ml-20m\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_DH8SxPH64nZ",
        "outputId": "38692978-bb8e-4c01-8ec8-0310336fa581"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   movieId                        title  \\\n",
              "0        1                    Toy Story   \n",
              "1        2                      Jumanji   \n",
              "2        3             Grumpier Old Men   \n",
              "3        4            Waiting to Exhale   \n",
              "4        5  Father of the Bride Part II   \n",
              "\n",
              "                                        genres  year  year_norm  \n",
              "0  Adventure Animation Children Comedy Fantasy  1995    0.83871  \n",
              "1                   Adventure Children Fantasy  1995    0.83871  \n",
              "2                               Comedy Romance  1995    0.83871  \n",
              "3                         Comedy Drama Romance  1995    0.83871  \n",
              "4                                       Comedy  1995    0.83871  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa336fb6-cc4b-47b6-9faf-46b0bf4efe73\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movieId</th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "      <th>year</th>\n",
              "      <th>year_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Toy Story</td>\n",
              "      <td>Adventure Animation Children Comedy Fantasy</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.83871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Jumanji</td>\n",
              "      <td>Adventure Children Fantasy</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.83871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Grumpier Old Men</td>\n",
              "      <td>Comedy Romance</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.83871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Waiting to Exhale</td>\n",
              "      <td>Comedy Drama Romance</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.83871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Father of the Bride Part II</td>\n",
              "      <td>Comedy</td>\n",
              "      <td>1995</td>\n",
              "      <td>0.83871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa336fb6-cc4b-47b6-9faf-46b0bf4efe73')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa336fb6-cc4b-47b6-9faf-46b0bf4efe73 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa336fb6-cc4b-47b6-9faf-46b0bf4efe73');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Loading movie\n",
        "movies = pd.read_csv(fpath+'/movies.csv')\n",
        "movies[\"year\"]=movies[\"title\"].apply(lambda x: x.strip()[-5:-1] if x.strip()[-5:-1][0:2] in ('18', '19', '20') else -1)\n",
        "movies[\"genres\"] = movies[\"genres\"].apply(lambda x: ' ' if x == '(no genres listed)' else ' '.join(x.split('|')) )\n",
        "movies[\"title\"]= movies.apply(lambda x: x[\"title\"][0:-7] if x[\"year\"] != -1 else x[\"title\"], axis=1)\n",
        "movies[\"year_norm\"] = movies[\"year\"].astype('int').apply(lambda x: -1 if x==-1 else (x-1891)/(2015-1891))\n",
        "movies.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# vect = CountVectorizer()\n",
        "# genre_vect = vect.fit_transform(movies[\"genres\"]).todense()\n",
        "# genre_vect= np.array(genre_vect)\n",
        "# movies[\"genres_vect\"] = [genre_vect[i] for i in range(genre_vect.shape[0])]"
      ],
      "metadata": {
        "id": "vVdhS5FbefiU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BERT"
      ],
      "metadata": {
        "id": "0DewCGPWlpjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tfhub_handle_encoder = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
        "# tfhub_handle_preprocess = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "\n",
        "# bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)\n",
        "# bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "CehlXf5_lpGS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# title_prep = bert_preprocess_model(\n",
        "#      movies['title']\n",
        "#     )"
      ],
      "metadata": {
        "id": "8wPPMz7SPB8Z"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# title_vect = bert_model( title_prep )['pooled_output']"
      ],
      "metadata": {
        "id": "znsX1BGblzAJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ratings"
      ],
      "metadata": {
        "id": "nUi_FsOPeKFG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "fiRtTNy1ScIa"
      },
      "outputs": [],
      "source": [
        "# user-wise train-test split\n",
        "def user_wise_split(userCol, test_size=0.25):\n",
        "    df = pd.read_csv(fpath+'/ratings.csv')\n",
        "    df[\"y\"] = df[\"rating\"]/2.5-1\n",
        "    all_user = df[userCol].drop_duplicates()\n",
        "    train_user, test_user = train_test_split(all_user, test_size=test_size)\n",
        "\n",
        "    train_ratings = df[df[userCol].isin(train_user)]\n",
        "    test_ratings = df[df[userCol].isin(test_user)]\n",
        "    return train_ratings, test_ratings\n",
        "\n",
        "train, test= user_wise_split(userCol,test_size= 0.35)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iejmAYEB4kjy"
      },
      "outputs": [],
      "source": [
        "top_k_item = 20000\n",
        "wu_size = 200\n",
        "max_item = wu_size\n",
        "\n",
        "top_items = train.groupby(itemCol).count().sort_values(by=userCol, ascending=False).head(top_k_item).index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIfY6FeqKqQ4"
      },
      "source": [
        "# Class  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mvnW0Fd52VkU"
      },
      "outputs": [],
      "source": [
        "class TimeTrachker():\n",
        "    \"\"\"Tracking runing time\"\"\"\n",
        "    def start(self):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def check(self, des = ''):\n",
        "        try:\n",
        "            if self.check_time is None:\n",
        "                self.check_time = self.start_time\n",
        "        except:\n",
        "            self.check_time = self.start_time\n",
        "        self.end_time = time.time()\n",
        "        dur = self.end_time - self.check_time\n",
        "        print(des + \" duration: \", dur)\n",
        "\n",
        "        self.check_time = time.time()\n",
        "        return dur\n",
        "\n",
        "    def stop(self, des = ''):\n",
        "        self.end_time = time.time()\n",
        "        dur = self.end_time - self.start_time\n",
        "        print(des + \" duration: \", dur)\n",
        "        self.start_time = time.time()\n",
        "        self.check_time = None\n",
        "        return dur\n",
        "\n",
        "timer = TimeTrachker()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Lb2Hx2rlWzmP"
      },
      "outputs": [],
      "source": [
        "def get_interaction_set(interaction, max_item = None, top_k_item = None):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        interaction: df[userCol, itemCol, y]: dữ liệu đầu vào\n",
        "        max_item: int: item num limit\n",
        "    Output:\n",
        "        df, itemCol: list, y: list, itemCol_str: string, userCol as index\n",
        "        list item sắp xếp theo giảm dần độ lớn rating\n",
        "    \"\"\"\n",
        "    items = interaction.groupby(itemCol).count().sort_values(by=userCol, ascending=False)\n",
        "    if top_k_item is not None:\n",
        "        top_items = items.head(top_k_item).index\n",
        "        interaction = interaction[interaction[itemCol].isin(top_items)]\n",
        "    else:\n",
        "        top_items = items.index\n",
        "\n",
        "    # Sắp xếp item theo thứ tự giảm dần rating (về sau cắt padding sẽ ưu tiên giữ lại item có rating cao)\n",
        "    rindex = interaction.groupby(userCol)[\"y\"].transform(lambda grp: grp.sort_values(ascending=False).index)\n",
        "    interaction = interaction.reindex(rindex)\n",
        "    \n",
        "    # Chuyển thành warm-up set theo từng user\n",
        "    interaction = interaction.groupby(\"userId\").agg({itemCol:list, \"y\":list})\n",
        "\n",
        "    # Giới hạn độ dài warm_up size\n",
        "    if max_item is not None:\n",
        "        interaction[itemCol] = interaction[itemCol].apply(lambda x: x[0:max_item])\n",
        "        interaction[\"y\"] = interaction[\"y\"].apply(lambda x: x[0:max_item])\n",
        "\n",
        "    return interaction, top_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jJySyZdU4Iou"
      },
      "outputs": [],
      "source": [
        "# Bulding model\n",
        "class Efficient_Rec(tf.keras.Model):\n",
        "    def __init__(self, encoder, wu_size= 200, use_tf_function=False):\n",
        "        super().__init__()\n",
        "        self.use_tf_function = use_tf_function\n",
        "        self.encoder = encoder\n",
        "        self.wu_size = wu_size\n",
        "\n",
        "    # from v2.2: chỉ groupby, không padding\n",
        "    @staticmethod\n",
        "    def get_interaction_set(interaction, max_item = None, top_k_item = None):\n",
        "        \"\"\"\n",
        "        Input:\n",
        "            interaction: df[userCol, itemCol, y]: dữ liệu đầu vào\n",
        "            max_item: int: item num limit\n",
        "        Output:\n",
        "            df, itemCol: list, y: list, itemCol_str: string, userCol as index\n",
        "            list item sắp xếp theo giảm dần độ lớn rating\n",
        "        \"\"\"\n",
        "        items = interaction.groupby(itemCol).count().sort_values(by=userCol, ascending=False)\n",
        "        if top_k_item is not None:\n",
        "            top_items = items.head(top_k_item).index\n",
        "            interaction = interaction[interaction[itemCol].isin(top_items)]\n",
        "        else:\n",
        "            top_items = items.index\n",
        "\n",
        "        # Sắp xếp item theo thứ tự giảm dần rating (về sau cắt padding sẽ ưu tiên giữ lại item có rating cao)\n",
        "        rindex = interaction.groupby(userCol)[\"y\"].transform(lambda grp: grp.sort_values(ascending=False).index)\n",
        "        interaction = interaction.reindex(rindex)\n",
        "        \n",
        "        # Chuyển thành warm-up set theo từng user\n",
        "        interaction = interaction.groupby(\"userId\").agg({itemCol:list, \"y\":list})\n",
        "\n",
        "        # Giới hạn độ dài warm_up size\n",
        "        if max_item is not None:\n",
        "            interaction[itemCol] = interaction[itemCol].apply(lambda x: x[0:max_item])\n",
        "            interaction[\"y\"] = interaction[\"y\"].apply(lambda x: x[0:max_item])\n",
        "\n",
        "        return interaction, top_items\n",
        "\n",
        "    @staticmethod\n",
        "    def padding_list(list_item, wu_size, value=0, is_padding=True):\n",
        "        series_item1 = list_item[0:wu_size]\n",
        "        if is_padding:\n",
        "            series_item1 = series_item1+[value]*(wu_size-len(series_item1))\n",
        "        return series_item1\n",
        "\n",
        "\n",
        "    def _preprocess(self, inputs, padding_size = 100):\n",
        "        \"\"\"\n",
        "        Padding về wu_size và mask_size, convert list of items => string of items\n",
        "        batch_inputs: df: itemStr, y\"\"\"\n",
        "\n",
        "        items_list, ratings_list = inputs\n",
        "\n",
        "        items   = items_list.apply(lambda x: ' '.join(list([str(i) for i in x])))\n",
        "        ratings =   np.stack( ratings_list.apply(lambda x: self.padding_list( x, padding_size  ) ) )\n",
        "\n",
        "        return items, ratings\n",
        "\n",
        "    def preprocessing_full_ft(self, inputs, padding_size = 100):\n",
        "        items_list, genres_list, years_list, ratings_list = inputs\n",
        "\n",
        "        items   = items_list.apply(lambda x: ' '.join(list([str(i) for i in x])))\n",
        "        ratings =   np.stack( ratings_list.apply(lambda x: self.padding_list( x, padding_size  ) ) )\n",
        "        genres = genres_list\n",
        "        years =  np.stack( years_list.apply(lambda x: self.padding_list( x, padding_size  ) ) )\n",
        "\n",
        "        return items,genres,years, ratings\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def get_top_cluster(scores, interaction_list, cluster_num=5):\n",
        "        interaction_list_ = interaction_list.copy()\n",
        "        idx = np.argsort(-scores.transpose(),axis=0)[:cluster_num]\n",
        "        interaction_list_[\"clusters\"] = [list(i) for i in idx.transpose()]\n",
        "        interaction_list_[\"scores\"] = [ list(scores[i][ind]) for i, ind in enumerate(idx.transpose()) ]\n",
        "        return interaction_list_\n",
        "\n",
        "    def minibatch_clustering(self, interaction_list, batch_size= 512):\n",
        "        chunks = [interaction_list[i:i+batch_size] for i in range(0,interaction_list.shape[0],batch_size)]\n",
        "        preds = []\n",
        "        for chunk in chunks:\n",
        "            if using_full_feature:\n",
        "                pred = self.encoder(\n",
        "                            self.preprocessing_full_ft( [chunk[itemCol], chunk[\"genres\"], chunk[\"year_norm\"], chunk[\"y\"]], \n",
        "                                                        padding_size = wu_size )\n",
        "                            ).numpy()\n",
        "            else:\n",
        "                pred = self.encoder(self._preprocess( [chunk[itemCol], chunk[\"y\"]], padding_size = wu_size )).numpy()\n",
        "\n",
        "            preds.append( pred )\n",
        "\n",
        "        return np.concatenate(preds)\n",
        "\n",
        "    @staticmethod\n",
        "    def chunk_explode(ratings, batch_size = 1024**2):\n",
        "        chunks = [ratings[i:i+batch_size] for i in range(0,ratings.shape[0],batch_size)]\n",
        "        explodes = []\n",
        "\n",
        "        # Todo: convert for loop to parallel\n",
        "        def chunk_process(chunk):\n",
        "            explode = chunk.explode([\"clusters\", \"scores\"])\n",
        "            explode[\"contribute_score\"] = explode[\"scores\"].astype(\"float64\")*explode[\"y\"]\n",
        "            explode = explode.groupby([\"clusters\", \"movieId\"]).agg({\n",
        "                \"contribute_score\": [\"mean\", \"count\"]\n",
        "            }).reset_index()\n",
        "            explode.columns = [\"clusters\", \"movieId\", \"mean\", \"count\"]\n",
        "\n",
        "            return explode\n",
        "\n",
        "        explodes = Parallel(n_jobs = -1, verbose = 1)(\n",
        "                    delayed(chunk_process)(chunk) for chunk in tqdm(chunks))\n",
        "        # combine results\n",
        "        gr = pd.concat(explodes, axis = 0)\n",
        "        gr[\"product\"] = gr[\"mean\"]*gr[\"count\"]\n",
        "        gr = gr.groupby([\"clusters\", \"movieId\"]).sum().reset_index()\n",
        "        gr[\"contribute_score\"] = gr[\"product\"]/gr[\"count\"]\n",
        "        gr = gr[[\"clusters\", \"movieId\", \"contribute_score\"]]\n",
        "        return gr\n",
        "\n",
        "    def get_shortlist(self, ratings, interaction_list= None, limit = 500, cluster_num = 5, batch_size=512):\n",
        "        timer.start()\n",
        "        if interaction_list is None:\n",
        "            interaction_list_, _ = self.get_interaction_set(  ratings, max_item = max_item, top_k_item = top_k_item  )\n",
        "        else:\n",
        "            interaction_list_ = interaction_list.copy()\n",
        "\n",
        "        scores = self.minibatch_clustering(interaction_list_, batch_size=batch_size)\n",
        "\n",
        "        # Limit number of cluster for each user\n",
        "        interaction_list_ = self.get_top_cluster(scores, interaction_list_, cluster_num= cluster_num)\n",
        "        timer.check(des = \"Get cluster\")\n",
        "\n",
        "        # Get shortlist for each cluster\n",
        "        ratings_ = ratings.copy().set_index(\"userId\")\n",
        "        ratings_ = ratings_[ratings_[\"y\"]>0]\n",
        "        ratings_ = ratings_.join(interaction_list_, rsuffix=\"_l\", how = \"inner\")\n",
        "        timer.check(des = \"Join interaction\")\n",
        "        ratings_ = self.chunk_explode(ratings_, batch_size= 1024*200)\n",
        "        timer.check(des = \"Chunk explode\")\n",
        "\n",
        "        ratings_[\"rank\"] = ratings_.groupby(\"clusters\")[\"contribute_score\"].rank(method='first', ascending=False)\n",
        "        ratings_ = ratings_[(ratings_[\"rank\"] <= limit)&(ratings_[\"contribute_score\"]>0)]\n",
        "        timer.check(des = \"Chunk explode\")\n",
        "\n",
        "        self.shortlist = ratings_\n",
        "\n",
        "        timer.stop(des = \"Total\")\n",
        "\n",
        "    @staticmethod\n",
        "    def left_anti_user_item_join( left, right ):\n",
        "        \"\"\"Fast left anijoin 2 dataframe by one column\"\"\"\n",
        "        wu_key = left[userCol].astype('str')+\"&\"+left[itemCol].astype('str')\n",
        "        blacklist = right[userCol].astype('str')+\"&\"+right[itemCol].astype('str')\n",
        "\n",
        "        key_diff = set(wu_key).difference(blacklist)\n",
        "        where_diff = wu_key.isin(key_diff)\n",
        "        output = left[where_diff]\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "    def batch_get_recommend(self, warm_up= None, historical_ratings = None, top_k = 10, is_remove_interacted = True, \n",
        "        batch_size=1024, reduce_method=\"random\", using_rapids= False, cluster_num= 5):\n",
        "        \"\"\"\n",
        "        reduce_method: str, 'random' or 'mean'\n",
        "        \"\"\"\n",
        "        print(\"historical_ratings shape \", historical_ratings.shape)\n",
        "        timer.start()\n",
        "        if warm_up is None:\n",
        "            if using_full_feature:\n",
        "                warm_up, _ = get_interaction_itemft_set( \n",
        "                     historical_ratings, movies\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "            else:\n",
        "                warm_up, _ = get_interaction_set( \n",
        "                         historical_ratings\n",
        "                        , max_item = max_item\n",
        "                        , top_k_item = top_k_item )\n",
        "\n",
        "        scores = self.minibatch_clustering(warm_up, batch_size=512)\n",
        "        wu = self.get_top_cluster( scores, warm_up, cluster_num= cluster_num)\n",
        "\n",
        "        wu = wu.explode([\"clusters\", \"scores\"]).reset_index()[[userCol, \"clusters\", \"scores\"]]\n",
        "        timer.check(des = \"Get cluster for user\")\n",
        "        print(\"wu shape \", wu.shape)\n",
        "        \n",
        "        user_num = wu[userCol].drop_duplicates().shape[0]\n",
        "        print(\"user_num \", user_num)\n",
        "\n",
        "        # cudf.from_pandas\n",
        "        if using_rapids:\n",
        "            wu = dd.from_pandas(wu)\n",
        "            historical_ratings = dd.from_pandas(historical_ratings.copy())\n",
        "\n",
        "        chunks = [wu[wu[userCol].isin(range(i,i+batch_size))] \n",
        "                  for i in range(0,user_num,batch_size)]\n",
        "\n",
        "        his_chunks = [historical_ratings[historical_ratings[userCol].isin(range(i,i+batch_size))] \n",
        "                        for i in range(0,user_num,batch_size)]\n",
        "       \n",
        "        shortlist = self.shortlist\n",
        "\n",
        "        def batch_join_process(chunk, his_chunk):\n",
        "            timer2 = TimeTrachker()\n",
        "            timer2.start()\n",
        "\n",
        "            wu = chunk.merge(shortlist, on=\"clusters\", how='inner')\n",
        "            print('''wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape: ''', wu.shape)\n",
        "            wu[\"matched_score\"] = wu[\"scores\"]*wu[\"contribute_score\"]\n",
        "\n",
        "            if reduce_method==\"mean\":\n",
        "                wu = wu.groupby([userCol, itemCol]).agg({\"matched_score\":'mean'}).reset_index()\n",
        "            \n",
        "            if reduce_method==\"random\":\n",
        "                # using drop_duplicates for boost speed, may reduce accuracy.\n",
        "                wu = wu.drop_duplicates(subset=[\"userId\", \"movieId\"])\n",
        "\n",
        "            print('''after reduce wu shape: ''', wu.shape)\n",
        "            timer2.check(des = \"reduce\")\n",
        "\n",
        "            if is_remove_interacted:\n",
        "                wu = self.left_anti_user_item_join( wu, historical_ratings )\n",
        "\n",
        "            print('''after remove interacted wu shape: ''', wu.shape)\n",
        "            timer2.check(des = \"remove interacted item\")\n",
        "\n",
        "            wu[\"rank\"] = wu.groupby(userCol)[\"matched_score\"].rank(method='first', ascending=False)\n",
        "            wu = wu[wu[\"rank\"]<= top_k]\n",
        "\n",
        "            timer2.stop(des = \"all chunk processing time\")\n",
        "\n",
        "            return wu \n",
        "        \n",
        "        timer.check(des = \"Prepare to join\")\n",
        "        wus = Parallel(n_jobs = -1, backend= 'threading', verbose = 1)(\n",
        "                    delayed(batch_join_process)(chunk, his_chunk) for chunk, his_chunk in tqdm(zip(chunks, his_chunks)))\n",
        "        \n",
        "        gc.collect()\n",
        "\n",
        "        timer.check(des = \"Join\")\n",
        "\n",
        "        output = pd.concat(wus, axis=0)\n",
        "\n",
        "        timer.stop(des = \"Total\")\n",
        "        return output\n",
        "\n",
        "    def release_cache(self):\n",
        "        self.interaction_list = None \n",
        "        gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sbp1tH7yUeI6"
      },
      "source": [
        "# Xây dựng encoder model\n",
        "Encoder =  interaction embedding + user feature embedding<br> \n",
        "interaction embedding = sum( interaction embedding các item i)<br> \n",
        "interaction embedding item i = rating x (embedding id sản phẩm + embedding item feature)<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxNyuo9-WJJG",
        "outputId": "916b3154-9232-4edf-953a-e167f4147898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 821 ms, sys: 407 ms, total: 1.23 s\n",
            "Wall time: 4.52 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Vectorize (encode + padding) item list\n",
        "max_vocab_size = len(top_items) # nếu số item có <= top_k_item => lấy số lượng item max\n",
        "items_str = ' '.join([str(i) for i in top_items])\n",
        "itemStr = itemCol+\"_str\"\n",
        "\n",
        "vectorizer = layers.TextVectorization( max_tokens= top_k_item, split='whitespace', output_sequence_length= wu_size, name = 'vectorizer')\n",
        "vectorizer.adapt( [items_str] ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1U7EQG6zWpi9"
      },
      "outputs": [],
      "source": [
        "class Broadcasting_Multiply(tf.keras.layers.Layer):\n",
        "    \"\"\"Nhân 2 layers khác shape với nhau, trong đó:\n",
        "    inputs=[layer1, layer2]\n",
        "    layer1.shape = (None, n_item, n_feature)\n",
        "    layer2.shape = (None, n_item)\n",
        "    (Chú ý đúng thứ tự)\n",
        "    \"\"\"\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x, y = inputs\n",
        "        deno = tf.expand_dims(tf.cast(tf.math.count_nonzero(y, axis=1), tf.float32), -1)\n",
        "        #we add the extra dimension:\n",
        "        y = K.expand_dims(y, axis=-1)\n",
        "        #we replicate the elements\n",
        "        y = K.repeat_elements(y, rep=x.shape[2], axis=-1)\n",
        "\n",
        "        return x * y, deno"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "--fbIsGLXjPD"
      },
      "outputs": [],
      "source": [
        "# Xây dựng mạng\n",
        "embedding_size = 173\n",
        "reps_size = 132\n",
        "preference_vector_size = 43\n",
        "\n",
        "@tf.function\n",
        "def avg_layer(z):\n",
        "    t = K.sum(z[0], axis=1)/z[1]\n",
        "    t = tf.clip_by_value( t, -1, 1 )\n",
        "    t = tf.where(tf.math.is_nan(t), tf.zeros_like(t), t)\n",
        "    return t\n",
        "\n",
        "\n",
        "def interaction_embedding():\n",
        "\n",
        "    input_wi = layers.Input(shape=(1,), name='input_wi')\n",
        "    wi = vectorizer(input_wi)\n",
        "    wi = layers.Embedding(input_dim= max_vocab_size, output_dim= embedding_size, mask_zero= True, name='ei')(wi)\n",
        "    # wi = layers.Dense(embedding_size, activation='sigmoid', use_bias = False, name='di')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='relu', use_bias = False, name='di1')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='relu', use_bias = False, name='di2')(wi)\n",
        "    # wi = layers.Dense(embedding_size, activation='sigmoid', use_bias = False, name='di3')(wi)\n",
        "\n",
        "    wr = layers.Input(shape=(wu_size,), name='warm_up_ratings')\n",
        "\n",
        "    ireps = Broadcasting_Multiply(name='mul')([wi, wr])\n",
        "    uprofile = layers.Lambda(lambda z: avg_layer(z) )(ireps)\n",
        "\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du1')(uprofile)\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du2')(uprofile)\n",
        "    # uprofile = layers.Dense( reps_size, activation='relu', name='du3')(uprofile)\n",
        "    # uprofile = layers.BatchNormalization(name='norm')(uprofile)\n",
        "    uprofile = layers.LayerNormalization(name='norm')(uprofile)\n",
        "    # uprofile = layers.Dense( reps_size, activation='relu', name='du4')(uprofile)\n",
        "    uprofile = layers.Dense(preference_vector_size, activation='sigmoid', name='clustering')(uprofile)\n",
        "    \n",
        "    \n",
        "    model = tf.keras.Model(inputs= [input_wi, wr], outputs=[uprofile])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "a7EW-lg9Cfi5"
      },
      "outputs": [],
      "source": [
        "# # Example of layer interaction embedding step by step\n",
        "# input_wi = [\"15 25 65 20 84\",  # 5 items\n",
        "#             \"51 54 45 21 24 83 81 76 74 75 72 48 29 38\",# 14 items\n",
        "#             \" \", # 0 item\n",
        "#             ] \n",
        "\n",
        "# tvectorizer = layers.TextVectorization( max_tokens= 17, split='whitespace', output_sequence_length= 10)\n",
        "# tvectorizer.adapt( input_wi ) \n",
        "\n",
        "# wi = tvectorizer(input_wi)\n",
        "# print(\"afer TextVectorization layer \\n\",wi)\n",
        "# wi = layers.Embedding(input_dim= 17, output_dim= 4, mask_zero= True, name='ei')(wi)\n",
        "# print(\"afer Embedding layer \\n\",wi)\n",
        "# wi = layers.Dense(3, activation='sigmoid',  use_bias = False, name='di')(wi)\n",
        "\n",
        "# wr = np.array([[0.5, 0.1, -0.5, 1, 0.25, 0, 0, 0, 0, 0], [0.25, 0.15, 0.5, 1, 0.25, 0.5, 0.1, -0.9, 0.4, -0.3], [0,0,0,0,0,0,0,0,0,0]])\n",
        "\n",
        "# ireps = Broadcasting_Multiply(name='mul')([wi, wr])\n",
        "# print(\"afer Multiply layer \\n\",ireps)\n",
        "# uprofile = layers.Lambda(lambda z: avg_layer(z) )(ireps)\n",
        "# print(\"afer Average layer \\n\",uprofile)\n",
        "\n",
        "# uprofile = layers.Dense( reps_size, activation='relu', name='du2')(uprofile)\n",
        "# uprofile = layers.LayerNormalization(name='norm')(uprofile)\n",
        "# uprofile = layers.Dense(5, activation='sigmoid', name='clustering')(uprofile)\n",
        "# print(\"afer Sigmoid layer \\n\",uprofile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cJMxOoxzXvr_"
      },
      "outputs": [],
      "source": [
        "# Kiểm tra tham số\n",
        "# interaction_embedding().summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "PuAM8w01Xy93"
      },
      "outputs": [],
      "source": [
        "# tf.keras.utils.plot_model( interaction_embedding() ,show_shapes=True, show_dtype=True, show_layer_names=True )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full feature encoder"
      ],
      "metadata": {
        "id": "5QdixqbCQdwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_interaction_itemft_set(interaction, movies, max_item = None, top_k_item = None):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        interaction: df[userCol, itemCol, y]: dữ liệu đầu vào\n",
        "        max_item: int: item num limit\n",
        "    Output:\n",
        "        df, itemCol: list, y: list, itemCol_str: string, userCol as index\n",
        "        list item sắp xếp theo giảm dần độ lớn rating\n",
        "    \"\"\"\n",
        "    items = interaction.groupby(itemCol).count().sort_values(by=userCol, ascending=False)\n",
        "    if top_k_item is not None:\n",
        "        top_items = items.head(top_k_item).index\n",
        "        interaction = interaction[interaction[itemCol].isin(top_items)]\n",
        "        movies = movies[movies[itemCol].isin(top_items)]\n",
        "    else:\n",
        "        top_items = items.index\n",
        "\n",
        "    interaction = interaction.merge(movies, on=[itemCol], how='left' )\n",
        "\n",
        "    # Sắp xếp item theo thứ tự giảm dần rating (về sau cắt padding sẽ ưu tiên giữ lại item có rating cao)\n",
        "    rindex = interaction.groupby(userCol)[\"y\"].transform(lambda grp: grp.sort_values(ascending=False).index)\n",
        "    interaction = interaction.reindex(rindex)\n",
        "    \n",
        "    # Chuyển thành warm-up set theo từng user\n",
        "    interaction = interaction.groupby(\"userId\").agg({itemCol:list, \"y\":list, \"genres\": list, \"year_norm\": list})\n",
        "\n",
        "    # Giới hạn độ dài warm_up size\n",
        "    if max_item is not None:\n",
        "        interaction[itemCol] = interaction[itemCol].apply(lambda x: x[0:max_item])\n",
        "        interaction[\"y\"] = interaction[\"y\"].apply(lambda x: x[0:max_item])\n",
        "\n",
        "    return interaction, top_items"
      ],
      "metadata": {
        "id": "8qsKzpVse4uZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genre_dims = 5\n",
        "max_genre_num = 20\n",
        "\n",
        "genre_vectorizer = layers.TextVectorization( max_tokens= 20, split='whitespace', output_sequence_length= wu_size, name = 'gvectorizer')\n",
        "genre_vectorizer.adapt( movies[\"genres\"] ) "
      ],
      "metadata": {
        "id": "Rj5L6BkQmgyw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def user_embedding():\n",
        "\n",
        "    # Warmup itemId\n",
        "    input_wi = layers.Input(shape=(1,), name='input_wi')\n",
        "    wi = vectorizer(input_wi)\n",
        "    wi = layers.Embedding(input_dim= max_vocab_size, output_dim= embedding_size, mask_zero= True, name='ei')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='relu', use_bias = False, name='di1')(wi)\n",
        "    wi = layers.Dense(embedding_size, activation='linear', use_bias = False, name='di2')(wi) # (batch_size, wu_size, embedding_size)\n",
        "\n",
        "    # Warmup genre\n",
        "    input_wg = layers.Input(shape=(1,), name='input_wg')\n",
        "    wg = genre_vectorizer(input_wg)\n",
        "    wg = layers.Embedding(input_dim= max_genre_num, output_dim= genre_dims, mask_zero= True, name='eg')(wi)\n",
        "    wg = layers.Lambda(lambda x: K.mean(x, axis=-1))(wg)\n",
        "    wg = layers.Dense(genre_dims, activation='relu', use_bias = False, name='dg1')(wg)\n",
        "    wg = layers.Dense(genre_dims, activation='linear', use_bias = False, name='dg2')(wg) # (batch_size, wu_size, genre_dims)\n",
        "\n",
        "    # Warmup year of movie\n",
        "    input_wy = layers.Input(shape=(wu_size,), name='input_wy')\n",
        "    wy = layers.Lambda(lambda x: K.expand_dims(x, axis=-1))(input_wy)\n",
        "\n",
        "    # Full features\n",
        "    wf = layers.Concatenate(axis=-1)([wi, wg, wy])\n",
        "    wf = layers.Dense( reps_size, activation='relu', name='wf1')(wf)\n",
        "    wf = layers.Dense( reps_size, activation='linear', name='wf2')(wf)\n",
        "\n",
        "    wr = layers.Input(shape=(wu_size,), name='warm_up_ratings')\n",
        "\n",
        "    ireps = Broadcasting_Multiply(name='mul')([wf, wr])\n",
        "    uprofile = layers.Lambda( avg_layer )(ireps) # (batch_size, wu_size)\n",
        "\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du1')(uprofile)\n",
        "    uprofile = layers.Dense( reps_size, activation='relu', name='du2')(uprofile)\n",
        "    uprofile = layers.LayerNormalization(name='norm')(uprofile)\n",
        "    uprofile = layers.Dense(preference_vector_size, activation='sigmoid', name='clustering')(uprofile)\n",
        "    \n",
        "    \n",
        "    model = tf.keras.Model(inputs= [input_wi, input_wg, input_wy, wr], outputs=[uprofile])\n",
        "    return model"
      ],
      "metadata": {
        "id": "v1BzQbjIQgq4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BISfMUNM37ug"
      },
      "source": [
        "# Evaluate model results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "83VIKSPGNrN6"
      },
      "outputs": [],
      "source": [
        "def model_evaluate(model, movies, df, is_full_ft = False ):\n",
        "    if not is_full_ft:\n",
        "        dfu, ttop_items = get_interaction_set( df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "        group_scores = model.encoder(model._preprocess( [dfu[itemCol], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "    else:\n",
        "        dfu, ttop_items = get_interaction_itemft_set( \n",
        "                     df, movies\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "        group_scores = model.encoder(model.preprocessing_full_ft( [dfu[itemCol], dfu[\"genres\"], dfu[\"year_norm\"], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "\n",
        "    print(\"SAMPLE INTERACTION EMBEDDING\")\n",
        "    print( np.max(group_scores), np.mean(group_scores), np.min(group_scores) )\n",
        "    print( group_scores[0:3] )\n",
        "\n",
        "    print(\"FEATURE PLOT\")\n",
        "    feature_plot( movies, df, group_scores)\n",
        "    \n",
        "    print(\"CLUSTER CHECKING\")\n",
        "    check_cluster(group_scores)\n",
        "    \n",
        "    print(\"SPECTROGRAM PLOT\")\n",
        "    plot_spectrogram(group_scores)\n",
        "\n",
        "def get_label(movies, df, is_encode = False):\n",
        "    movies[\"genres_list\"] = movies[\"genres\"].apply(lambda x: x.split(' '))\n",
        "    movie_genres = movies.explode(\"genres_list\")\n",
        "    gr = df.merge(movie_genres, on=\"movieId\").groupby([\"userId\", \"genres_list\"])[\"movieId\"].count().reset_index()\n",
        "    gr[\"rank\"] = gr.groupby(\"userId\")[\"movieId\"].rank(method='first', ascending=False)\n",
        "\n",
        "    labels = gr[gr[\"rank\"] ==1].set_index(\"userId\")\n",
        "    # labels[\"pred_max_ind\"] = np.argmax(group_scores, axis=1)\n",
        "\n",
        "    if is_encode:\n",
        "        label_enc = LabelEncoder()\n",
        "        labels[\"label\"] = label_enc.fit_transform(labels[\"genres_list\"])\n",
        "\n",
        "    return labels\n",
        "\n",
        "def feature_plot( movies, df, group_scores ):\n",
        "    tlabels = get_label(movies, df)\n",
        "\n",
        "    tsne = PCA(n_components=2, random_state=123)\n",
        "    # tsne = TSNE(n_components=2, random_state=123)\n",
        "    z = tsne.fit_transform(group_scores) \n",
        "\n",
        "    df = pd.DataFrame()\n",
        "    df[\"y\"] = tlabels[\"genres_list\"]\n",
        "    df[\"comp-1\"] = z[:,0]\n",
        "    df[\"comp-2\"] = z[:,1]\n",
        "\n",
        "    plt.rcParams[\"figure.figsize\"] = (8,8)\n",
        "    sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
        "                    palette=\"Paired\" ,#sns.color_palette(\"hls\", 3),\n",
        "                    data=df)#.set(title=\"Iris data T-SNE projection\") \n",
        "    plt.show()\n",
        "\n",
        "def check_cluster(group_scores):\n",
        "    # Kiểm tra số user trong mỗi cụm có bị vón cục\n",
        "    ugs= np.argmax(group_scores, axis=1)\n",
        "    for i in range(50):\n",
        "        print(i,': ', np.sum(ugs==i) )\n",
        "\n",
        "def plot_spectrogram(group_scores):\n",
        "    # Sort theo user_group + draw sigmoid/softmax layer\n",
        "    plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "    k =100\n",
        "    a = group_scores\n",
        "    ind = np.argmax(group_scores, axis=1)\n",
        "    plt.imshow( a[np.argsort(ind)][0:k] )\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "_cs4Ci70vrkA"
      },
      "outputs": [],
      "source": [
        "def model_plot(model, movies, df, is_full_ft = False):\n",
        "    if not is_full_ft:\n",
        "        dfu, ttop_items = get_interaction_set( df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "        group_scores = model.encoder(model._preprocess( [dfu[itemCol], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "    else:\n",
        "        dfu, ttop_items = get_interaction_itemft_set( \n",
        "                     df, movies\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "        group_scores = model.encoder(model.preprocessing_full_ft( [dfu[itemCol], dfu[\"genres\"], dfu[\"year_norm\"], dfu[\"y\"]], padding_size = wu_size )).numpy()\n",
        "    print(\"FEATURE PLOT\")\n",
        "    feature_plot( movies, df, group_scores)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfUOMI8subTw"
      },
      "source": [
        "# Warm start user"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQtBh9xFunkU",
        "outputId": "4cfa359c-30a8-4767-95f9-fa534a585251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32149, 6)\n",
            "CPU times: user 1.19 ms, sys: 0 ns, total: 1.19 ms\n",
            "Wall time: 1.2 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "u_train_from = 0\n",
        "u_train_to = u_train_from + 130000\n",
        "u_test = u_train_to + 5000\n",
        "\n",
        "using_full_feature = True\n",
        "\n",
        "def get_labeled_data(df):\n",
        "    if using_full_feature:\n",
        "        interact_df, _ = get_interaction_itemft_set( \n",
        "                     df, movies\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    else:\n",
        "        interact_df, _ = get_interaction_set( \n",
        "                     df\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "    labels = get_label( movies, df, is_encode = True)\n",
        "    interact_df[\"label\"] = labels[\"label\"]\n",
        "    return interact_df#[[\"movieId\",\"y\",\"label\"]]\n",
        "try:\n",
        "    train_warm\n",
        "except:\n",
        "    # if exists, do not rerun\n",
        "    train_warm =  get_labeled_data( train[(train[userCol]>u_train_from)&(train[userCol]<u_train_to)] )\n",
        "    train_warm[\"rating_num\"] = train_warm.apply(lambda x: len(x[\"y\"]), axis=1)\n",
        "    # pretrain with warm start user\n",
        "    train_warm = train_warm[train_warm[\"rating_num\"]>=100]\n",
        "\n",
        "print( train_warm.shape )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0VaSsrviHLH",
        "outputId": "566976c8-eccd-4b43-f6d1-f8cffb198c99"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4933"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "aGY_dv9cV3Br"
      },
      "outputs": [],
      "source": [
        "# x = train[[\"userId\", \"rating\"]].groupby(\"userId\").count()\n",
        "# x[\"rating_num_clip\"] = x[\"rating\"].clip(0, 700).apply(lambda x: int(x/20)*20)\n",
        "# x.groupby(\"rating_num_clip\").count().plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "uFZiUT4FXHqn"
      },
      "outputs": [],
      "source": [
        "# x.groupby(\"rating_num_clip\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE0hPo7UFNkV",
        "outputId": "9e70efce-a5a8-4ac7-fe1d-9c7bc96615b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "150"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wO4EX1_Z-h3"
      },
      "source": [
        "# supervised constrastive "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "hQ-pwUZafD__"
      },
      "outputs": [],
      "source": [
        "class SupervisedContrastiveLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "TbltflgfUmXf"
      },
      "outputs": [],
      "source": [
        "# Thực hiện training\n",
        "def _supervised_constrastive_train_step(self, inputs):\n",
        "    items_pd, ratings_pd, labels = inputs[\"movieId\"], inputs[\"y\"], inputs[\"label\"]\n",
        "    items, ratings = self._preprocess((items_pd, ratings_pd), wu_size)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Interaction embedding\n",
        "        vec = self.encoder([items, ratings])\n",
        "\n",
        "        average_loss = self.loss(labels, vec)\n",
        "\n",
        "    # Apply an optimization step\n",
        "    variables = self.trainable_variables \n",
        "    gradients = tape.gradient(average_loss, variables)\n",
        "    \n",
        "    # Gradient clipping\n",
        "    # gradients = [None if gradient is None else tf.clip_by_value(gradient, -0.1, 0.1)\n",
        "    #              for gradient in gradients]\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "\n",
        "Efficient_Rec._supervised_constrastive_train_step = _supervised_constrastive_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "qSr05iptaPha"
      },
      "outputs": [],
      "source": [
        "# Thực hiện minibatch training\n",
        "def _spv_constrastive_train_minibatch_step(self, inputs, batch_size):\n",
        "    df = inputs.copy()\n",
        "    chunks = [df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]\n",
        "    losses = []\n",
        "    for chunk in chunks:\n",
        "        loss = self._supervised_constrastive_train_step(chunk)\n",
        "        losses.append(loss[\"batch_loss\"].numpy())\n",
        "        print(loss)\n",
        "        gc.collect()\n",
        "    return np.mean(losses)\n",
        "\n",
        "Efficient_Rec._spv_constrastive_train_minibatch_step = _spv_constrastive_train_minibatch_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "uBCoJlJMdB7y"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model = Efficient_Rec( encoder = interaction_embedding(), \n",
        "                      wu_size = wu_size,\n",
        "                      use_tf_function=False)\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate = 0.001),\n",
        "    loss= TripletSemiHardLoss() # SupervisedContrastiveLoss(temperature = 0.05),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "It6_5yszGfK7"
      },
      "outputs": [],
      "source": [
        "# Load trained model\n",
        "# latest = tf.train.latest_checkpoint(\"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/\")\n",
        "# model.encoder.load_weights(latest)\n",
        "# test_set = train[(train[userCol]>15000)&(train[userCol]<20000)]\n",
        "# model_plot(model, movies, test_set )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "VoepslyXhaQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e38395-256c-4002-8412-4658877c2650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.72 µs\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Train new model\n",
        "# epochs= 6\n",
        "# test_set = train[(train[userCol]>15000)&(train[userCol]<20000)]\n",
        "# model_plot(model, movies, test_set )\n",
        "# for n in range(epochs):\n",
        "#   print(n, \"/\", epochs, \": \", model._spv_constrastive_train_minibatch_step(train_warm.sample(frac=1.), batch_size=512))\n",
        "#   model_plot(model, movies, test_set )\n",
        "#   gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "M9_P8ZBsFGJb"
      },
      "outputs": [],
      "source": [
        "# model.encoder.save_weights(\"/content/gdrive/MyDrive/RECOMMENDER_STUDIES/data/encoder_v6\",save_format='tf')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ZZUCY20TSjFk"
      },
      "outputs": [],
      "source": [
        "# model_evaluate(model, movies, \n",
        "#                warm_up_mask[(warm_up_mask[userCol]>u_train_to)&(warm_up_mask[userCol]<=u_test)])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full feature supervised contrastive"
      ],
      "metadata": {
        "id": "0scDXl1QiiA6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Thực hiện training\n",
        "def _supervised_constrastive_fullft_train_step(self, inputs):\n",
        "    items_pd, ratings_pd, genres_pd, years_pd, labels = inputs[\"movieId\"], inputs[\"y\"], inputs[\"genres\"], inputs[\"year_norm\"], inputs[\"label\"]\n",
        "    items,genres,years, ratings = self.preprocessing_full_ft((items_pd, genres_pd, years_pd, ratings_pd), wu_size)\n",
        "\n",
        "    # genres = genres_pd\n",
        "    # years = np.stack( years_pd.apply(lambda x: self.padding_list( x, wu_size ) ) )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Interaction embedding\n",
        "        vec = self.encoder([items, genres, years, ratings])\n",
        "\n",
        "        average_loss = self.loss(labels, vec)\n",
        "\n",
        "    # Apply an optimization step\n",
        "    variables = self.trainable_variables \n",
        "    gradients = tape.gradient(average_loss, variables)\n",
        "    \n",
        "    # Gradient clipping\n",
        "    # gradients = [None if gradient is None else tf.clip_by_value(gradient, -0.1, 0.1)\n",
        "    #              for gradient in gradients]\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "\n",
        "Efficient_Rec._supervised_constrastive_fullft_train_step = _supervised_constrastive_fullft_train_step"
      ],
      "metadata": {
        "id": "YxZfiv2hihsn"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Thực hiện minibatch training\n",
        "def _spv_constrastive_train_minibatch_step_fullft(self, inputs, batch_size):\n",
        "    df = inputs.copy()\n",
        "    chunks = [df[i:i+batch_size] for i in range(0,df.shape[0],batch_size)]\n",
        "    losses = []\n",
        "    for chunk in chunks:\n",
        "        loss = self._supervised_constrastive_fullft_train_step(chunk)\n",
        "        losses.append(loss[\"batch_loss\"].numpy())\n",
        "        print(loss)\n",
        "        gc.collect()\n",
        "    return np.mean(losses)\n",
        "\n",
        "Efficient_Rec._spv_constrastive_train_minibatch_step_fullft = _spv_constrastive_train_minibatch_step_fullft"
      ],
      "metadata": {
        "id": "C36rRVGXkTTC"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model = Efficient_Rec( encoder = user_embedding(), \n",
        "                      wu_size = wu_size,\n",
        "                      use_tf_function=False)\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(learning_rate = 0.001),\n",
        "    loss= TripletSemiHardLoss() # SupervisedContrastiveLoss(temperature = 0.05),\n",
        ")"
      ],
      "metadata": {
        "id": "1VfvLQkWkbOp"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train new model\n",
        "epochs= 3\n",
        "test_set = train[(train[userCol]>0)&(train[userCol]<5000)]\n",
        "model_plot(model, movies, test_set, is_full_ft= True )\n",
        "for n in range(epochs):\n",
        "  print(n, \"/\", epochs, \": \", model._spv_constrastive_train_minibatch_step_fullft(train_warm.sample(frac=.5), batch_size=512))\n",
        "  model_plot(model, movies, test_set, is_full_ft= True )\n",
        "  gc.collect()"
      ],
      "metadata": {
        "id": "QhD9oZkHmu5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgfpZRoGF1KK"
      },
      "source": [
        "# Pick item pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "cwQnzbWCxd9u"
      },
      "outputs": [],
      "source": [
        "test_warm_up, test_mask = train_test_split(test, test_size= 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_items = test.groupby(itemCol).count().sort_values(by=userCol, ascending=False).head(1000).index"
      ],
      "metadata": {
        "id": "qiobZsmFVxA8"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQtrddWcEaoY",
        "outputId": "56547904-1ba4-4e0c-ebb5-b2fea3850152"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get cluster duration:  5.929877758026123\n",
            "Join interaction duration:  1.031590223312378\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s][Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "100%|██████████| 25/25 [00:20<00:00,  1.22it/s]\n",
            "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:   22.9s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk explode duration:  23.29566478729248\n",
            "Chunk explode duration:  0.012814521789550781\n",
            "Total duration:  30.274289846420288\n",
            "CPU times: user 12.7 s, sys: 979 ms, total: 13.7 s\n",
            "Wall time: 30.7 s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "# Item catalog of shortlist based in mesuable item in test (for evaluation process)\n",
        "model.get_shortlist( \n",
        "    ratings = train[ train[userCol].isin(train_warm.index) & train[itemCol].isin( test_items )],\n",
        "    interaction_list = train_warm,\n",
        "    limit = 50, \n",
        "    cluster_num = 5\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "0EvrD1tOVkXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b56b2c-6ba9-41f4-b863-27078081da95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1232"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "pO4O1LwBXrOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "759730bf-ebaf-4400-d0d3-9118ab77328b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       clusters  movieId  contribute_score  rank\n",
              "27            0       50          0.748354  10.0\n",
              "39            0      111          0.701242  46.0\n",
              "99            0      296          0.754827   6.0\n",
              "107           0      318          0.778459   2.0\n",
              "166           0      527          0.756872   4.0\n",
              "...         ...      ...               ...   ...\n",
              "36560        42    58559          0.774628   2.0\n",
              "36561        42    59315          0.671401  49.0\n",
              "36562        42    60069          0.676467  42.0\n",
              "36567        42    68358          0.683102  36.0\n",
              "36577        42    79132          0.735814  12.0\n",
              "\n",
              "[1900 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65832a75-d486-4c86-b7ad-45b4e2fb4251\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clusters</th>\n",
              "      <th>movieId</th>\n",
              "      <th>contribute_score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>50</td>\n",
              "      <td>0.748354</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>0</td>\n",
              "      <td>111</td>\n",
              "      <td>0.701242</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>0</td>\n",
              "      <td>296</td>\n",
              "      <td>0.754827</td>\n",
              "      <td>6.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>0</td>\n",
              "      <td>318</td>\n",
              "      <td>0.778459</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>0</td>\n",
              "      <td>527</td>\n",
              "      <td>0.756872</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36560</th>\n",
              "      <td>42</td>\n",
              "      <td>58559</td>\n",
              "      <td>0.774628</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36561</th>\n",
              "      <td>42</td>\n",
              "      <td>59315</td>\n",
              "      <td>0.671401</td>\n",
              "      <td>49.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36562</th>\n",
              "      <td>42</td>\n",
              "      <td>60069</td>\n",
              "      <td>0.676467</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36567</th>\n",
              "      <td>42</td>\n",
              "      <td>68358</td>\n",
              "      <td>0.683102</td>\n",
              "      <td>36.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36577</th>\n",
              "      <td>42</td>\n",
              "      <td>79132</td>\n",
              "      <td>0.735814</td>\n",
              "      <td>12.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1900 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65832a75-d486-4c86-b7ad-45b4e2fb4251')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65832a75-d486-4c86-b7ad-45b4e2fb4251 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65832a75-d486-4c86-b7ad-45b4e2fb4251');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "model.shortlist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "a1MUU9bdHQAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18e82d4a-16a0-4b57-b6e8-dd783957b57a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "historical_ratings shape  (3487378, 5)\n",
            "Get cluster for user duration:  25.941869497299194\n",
            "wu shape  (242365, 3)\n",
            "user_num  48473\n",
            "Prepare to join duration:  0.49378228187561035\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (898000, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (897500, 6)\n",
            "after reduce wu shape: after reduce wu shape:  (266602, 3)\n",
            "reduce duration:  77.08618831634521\n",
            " (266103, 3)\n",
            "reduce duration:  77.24959659576416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "5it [01:29, 17.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "after remove interacted wu shape: after remove interacted wu shape:  (243896, 3)\n",
            "remove interacted item duration:  11.885223627090454\n",
            " (243113, 3)\n",
            "remove interacted item duration:  11.723360776901245\n",
            "all chunk processing time duration: all chunk processing time duration:  89.07488059997559\n",
            " 89.07360601425171\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (898750, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(883500, 6)\n",
            "after reduce wu shape:  (267648, 3)\n",
            "reduce duration:  75.97209024429321\n",
            "after reduce wu shape:  after remove interacted wu shape:  (244871, 3)\n",
            "(261518, 3)\n",
            "reduce duration:  83.81065630912781\n",
            "remove interacted item duration:  7.986430883407593\n",
            "all chunk processing time duration:  88.642009973526\n",
            "after remove interacted wu shape:  (238869, 3)\n",
            "remove interacted item duration:  5.699965715408325\n",
            "wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape:  (909250, 6)\n",
            "all chunk processing time duration:  91.08927798271179\n",
            "after reduce wu shape:  (269506, 3)\n",
            "reduce duration:  37.745139360427856\n",
            "after remove interacted wu shape:  (246624, 3)\n",
            "remove interacted item duration:  5.7618067264556885\n",
            "all chunk processing time duration:  43.580241203308105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  3.7min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Join duration:  222.69747757911682\n",
            "Total duration:  249.1515555381775\n",
            "CPU times: user 4min 20s, sys: 18.1 s, total: 4min 38s\n",
            "Wall time: 4min 9s\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "top_k = 50\n",
        "\n",
        "y_pred = model.batch_get_recommend(\n",
        "        historical_ratings= test_warm_up, \n",
        "        top_k = top_k, is_remove_interacted = True, \n",
        "        batch_size= 1024*10,\n",
        "        reduce_method=\"mean\", \n",
        "        cluster_num= 5, \n",
        "        using_rapids= False\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "wFw_92XSRg3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76ed4e6d-1f68-4236-bcb2-838576bc8d95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9uEbFU-UEgxQ",
        "outputId": "eacd4c2a-8040-4271-8172-26c9f3a36109"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        userId  movieId  matched_score  rank\n",
              "0            3       29       0.680887  38.0\n",
              "2            3       50       0.735280   7.0\n",
              "3            3      110       0.677473  43.0\n",
              "5            3      293       0.682837  32.0\n",
              "6            3      296       0.718139  11.0\n",
              "...        ...      ...            ...   ...\n",
              "269500   51199     6016       0.706396  14.0\n",
              "269501   51199     7153       0.688699  27.0\n",
              "269502   51199     7361       0.688033  30.0\n",
              "269503   51199    44555       0.703734  16.0\n",
              "269504   51199    58559       0.683819  34.0\n",
              "\n",
              "[891300 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b02b6175-29ed-49b4-b50c-317444601ba1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>matched_score</th>\n",
              "      <th>rank</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.680887</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>0.735280</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>110</td>\n",
              "      <td>0.677473</td>\n",
              "      <td>43.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3</td>\n",
              "      <td>293</td>\n",
              "      <td>0.682837</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>296</td>\n",
              "      <td>0.718139</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269500</th>\n",
              "      <td>51199</td>\n",
              "      <td>6016</td>\n",
              "      <td>0.706396</td>\n",
              "      <td>14.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269501</th>\n",
              "      <td>51199</td>\n",
              "      <td>7153</td>\n",
              "      <td>0.688699</td>\n",
              "      <td>27.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269502</th>\n",
              "      <td>51199</td>\n",
              "      <td>7361</td>\n",
              "      <td>0.688033</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269503</th>\n",
              "      <td>51199</td>\n",
              "      <td>44555</td>\n",
              "      <td>0.703734</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269504</th>\n",
              "      <td>51199</td>\n",
              "      <td>58559</td>\n",
              "      <td>0.683819</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>891300 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b02b6175-29ed-49b4-b50c-317444601ba1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b02b6175-29ed-49b4-b50c-317444601ba1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b02b6175-29ed-49b4-b50c-317444601ba1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "c8yrKhc16vyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b130ada2-79c4-4a15-aa35-8ca56ceb7057"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49.66012926231335"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "y_pred.shape[0]/y_pred[userCol].drop_duplicates().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "_IRQdUmSRJkA"
      },
      "outputs": [],
      "source": [
        "y_true = test\n",
        "y_true[\"is_fav\"] = y_true[\"rating\"].apply(lambda x: 1 if x>2.5 else 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true"
      ],
      "metadata": {
        "id": "4sWTAK2-dYbT",
        "outputId": "6f7c394c-769e-45da-c4ad-47c168acda71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          userId  movieId  rating   timestamp    y  is_fav\n",
              "236            3        1     4.0   944919407  0.6       1\n",
              "237            3       24     3.0   945176048  0.2       1\n",
              "238            3       32     4.0   944918047  0.6       1\n",
              "239            3       50     5.0   944918018  1.0       1\n",
              "240            3      160     3.0   945176048  0.2       1\n",
              "...          ...      ...     ...         ...  ...     ...\n",
              "19999630  138489     2959     4.5  1352990114  0.8       1\n",
              "19999631  138489     3671     4.0  1352989107  0.6       1\n",
              "19999632  138489     4973     4.0  1352990124  0.6       1\n",
              "19999633  138489     5291     4.5  1352990158  0.8       1\n",
              "19999634  138489    58559     4.0  1352989309  0.6       1\n",
              "\n",
              "[6974757 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1789b9a9-0209-4b30-a061-d45fdf87f9dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>y</th>\n",
              "      <th>is_fav</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>944919407</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>3.0</td>\n",
              "      <td>945176048</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>3</td>\n",
              "      <td>32</td>\n",
              "      <td>4.0</td>\n",
              "      <td>944918047</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>944918018</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>3</td>\n",
              "      <td>160</td>\n",
              "      <td>3.0</td>\n",
              "      <td>945176048</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999630</th>\n",
              "      <td>138489</td>\n",
              "      <td>2959</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1352990114</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999631</th>\n",
              "      <td>138489</td>\n",
              "      <td>3671</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1352989107</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999632</th>\n",
              "      <td>138489</td>\n",
              "      <td>4973</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1352990124</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999633</th>\n",
              "      <td>138489</td>\n",
              "      <td>5291</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1352990158</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19999634</th>\n",
              "      <td>138489</td>\n",
              "      <td>58559</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1352989309</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6974757 rows × 6 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1789b9a9-0209-4b30-a061-d45fdf87f9dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1789b9a9-0209-4b30-a061-d45fdf87f9dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1789b9a9-0209-4b30-a061-d45fdf87f9dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "MWcFUMZ0KoSm"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    y_true: dataframe: user_id, item_id, is_fav (1 true, 0 false)\n",
        "    y_pred: dataframe: user_id, item_id\n",
        "    return:\n",
        "    precision@k, recall@k\n",
        "    \"\"\"\n",
        "    y_pred2 = y_pred.copy()\n",
        "    y_pred2[\"is_rec\"] = 1\n",
        "    y_true2 = y_true.copy()\n",
        "\n",
        "    total1 = y_true2.merge(y_pred2, on=[userCol, itemCol], how = 'left')\n",
        "    total1[\"rec_fav\"] = total1[\"is_rec\"].fillna(0) * total1[\"is_fav\"]\n",
        "\n",
        "    # Precision\n",
        "    p = total1[\"rec_fav\"].sum() / total1[\"is_rec\"].sum()\n",
        "\n",
        "    # Recall\n",
        "    r = total1[\"rec_fav\"].sum() / total1[\"is_fav\"].sum()\n",
        "\n",
        "    print(\"Rec matched: \", total1[\"is_rec\"].sum())\n",
        "    print(\"All labels: \", total1[\"is_fav\"].sum())\n",
        "\n",
        "    return p, r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "D9AtAbTSOVbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2756295c-bed7-492d-d8cd-9a7df48c9ddf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rec matched:  97954.0\n",
            "All labels:  5749935\n"
          ]
        }
      ],
      "source": [
        "precision, recall = evaluate_model(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "N2xZOMMPPcsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55f1632-1aa1-4fa5-9fd9-ea190c78851f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision : 0.9536415051963166\n"
          ]
        }
      ],
      "source": [
        "print(\"Precision :\", precision)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall"
      ],
      "metadata": {
        "id": "rBz4wfdJQrx1",
        "outputId": "eea82822-df0c-4e54-8244-7e4b3921bf8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.016245922779996643"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate based on rated item"
      ],
      "metadata": {
        "id": "jghjiVolllOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "def evaluate_model(model, y_true, warm_up= None, historical_ratings = None, top_k = 10, is_remove_interacted = True, \n",
        "    batch_size=1024*10, reduce_method=\"random\", cluster_num= 5):\n",
        "    \"\"\"\n",
        "    reduce_method: str, 'random' or 'mean'\n",
        "    \"\"\"\n",
        "    print(\"historical_ratings shape \", historical_ratings.shape)\n",
        "    timer.start()\n",
        "    if warm_up is None:\n",
        "        warm_up, _ = model.get_interaction_set( \n",
        "                     historical_ratings\n",
        "                    , max_item = max_item\n",
        "                    , top_k_item = top_k_item )\n",
        "\n",
        "    scores = model.minibatch_clustering(warm_up, batch_size=512)\n",
        "    wu = model.get_top_cluster( scores, warm_up, cluster_num= cluster_num)\n",
        "\n",
        "    wu = wu.explode([\"clusters\", \"scores\"]).reset_index()[[userCol, \"clusters\", \"scores\"]]\n",
        "    timer.check(des = \"Get cluster for user\")\n",
        "    print(\"wu shape \", wu.shape)\n",
        "    \n",
        "    user_num = wu[userCol].drop_duplicates().shape[0]\n",
        "    print(\"user_num \", user_num)\n",
        "\n",
        "    chunks = [wu[wu[userCol].isin(range(i,i+batch_size))] \n",
        "              for i in range(0,user_num,batch_size)]\n",
        "\n",
        "    his_chunks = [historical_ratings[historical_ratings[userCol].isin(range(i,i+batch_size))] \n",
        "                    for i in range(0,user_num,batch_size)]\n",
        "   \n",
        "    shortlist = model.shortlist\n",
        "\n",
        "    def batch_join_process(chunk, his_chunk):\n",
        "        timer2 = TimeTrachker()\n",
        "        timer2.start()\n",
        "\n",
        "        wu = chunk.merge(shortlist, on=\"clusters\", how='inner')\n",
        "        print('''wu = chunk.merge(shortlist, on=\"clusters\", how='inner') : wu shape: ''', wu.shape)\n",
        "        wu[\"matched_score\"] = wu[\"scores\"]*wu[\"contribute_score\"]\n",
        "\n",
        "        if reduce_method==\"mean\":\n",
        "            wu = wu.groupby([userCol, itemCol]).agg({\"matched_score\":'mean'}).reset_index()\n",
        "        \n",
        "        if reduce_method==\"random\":\n",
        "            # using drop_duplicates for boost speed, may reduce accuracy.\n",
        "            wu = wu.drop_duplicates(subset=[\"userId\", \"movieId\"])\n",
        "\n",
        "        print('''after reduce wu shape: ''', wu.shape)\n",
        "        timer2.check(des = \"reduce\")\n",
        "\n",
        "        if is_remove_interacted:\n",
        "            wu = model.left_anti_user_item_join( wu, historical_ratings )\n",
        "\n",
        "        # remove unrated item\n",
        "        wu = wu.merge(y_true, on= [userCol, itemCol], how='outer')\n",
        "        wu = wu[wu[\"y\"].notnull()]\n",
        "\n",
        "        print('''after remove interacted wu shape: ''', wu.shape)\n",
        "        timer2.check(des = \"remove interacted item\")\n",
        "\n",
        "        wu[\"rank\"] = wu.groupby(userCol)[\"matched_score\"].rank(method='first', ascending=False)\n",
        "        wu = wu[wu[\"rank\"]<= top_k]\n",
        "\n",
        "        timer2.stop(des = \"all chunk processing time\")\n",
        "\n",
        "        return wu \n",
        "    \n",
        "    timer.check(des = \"Prepare to join\")\n",
        "    wus = Parallel(n_jobs = -1, backend= 'threading', verbose = 1)(\n",
        "                delayed(batch_join_process)(chunk, his_chunk) for chunk, his_chunk in tqdm(zip(chunks, his_chunks)))\n",
        "    \n",
        "    gc.collect()\n",
        "\n",
        "    timer.check(des = \"Join\")\n",
        "\n",
        "    output = pd.concat(wus, axis=0)\n",
        "\n",
        "    timer.stop(des = \"Total\")\n",
        "    return output\n",
        "\n",
        "\n",
        "eval_tbl = evaluate_model(\n",
        "        model, y_true,\n",
        "        historical_ratings= test_warm_up, \n",
        "        top_k = top_k, is_remove_interacted = True, \n",
        "        batch_size= 1024*5,\n",
        "        reduce_method=\"random\", \n",
        "        cluster_num= 5\n",
        "    )"
      ],
      "metadata": {
        "id": "PdZlub9SltYL",
        "outputId": "2a553d58-809a-48ee-b9fa-2e2b09f76ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "historical_ratings shape  (3487378, 5)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'genres'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-4bbaae9394b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'def evaluate_model(model, y_true, warm_up= None, historical_ratings = None, top_k = 10, is_remove_interacted = True, \\n    batch_size=1024*10, reduce_method=\"random\", cluster_num= 5):\\n    \"\"\"\\n    reduce_method: str, \\'random\\' or \\'mean\\'\\n    \"\"\"\\n    print(\"historical_ratings shape \", historical_ratings.shape)\\n    timer.start()\\n    if warm_up is None:\\n        warm_up, _ = model.get_interaction_set( \\n                     historical_ratings\\n                    , max_item = max_item\\n                    , top_k_item = top_k_item )\\n\\n    scores = model.minibatch_clustering(warm_up, batch_size=512)\\n    wu = model.get_top_cluster( scores, warm_up, cluster_num= cluster_num)\\n\\n    wu = wu.explode([\"clusters\", \"scores\"]).reset_index()[[userCol, \"clusters\", \"scores\"]]\\n    timer.check(des = \"Get cluster for user\")\\n    print(\"wu shape \", wu.shape)\\n    \\n    user_num = wu[userCol].drop_duplicates().shape[0]\\n    print(\"user_num \", user_num)\\n\\n    chunks = [wu[wu[userCol].isin(range(i,i+batch_size))] \\n              for i in range(0,user_num,batch_size)]\\n\\n    his_chunks = [historical_ratings[historical_ratings[userCol].isin(range(i,i+batch_size))] \\n                    for i in range(0,user_num,batch_size)]\\n   \\n    shortlist = model.shortlist\\n\\n    def batch_join_process(chunk, his_chunk):\\n   ...\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model, y_true, warm_up, historical_ratings, top_k, is_remove_interacted, batch_size, reduce_method, cluster_num)\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-0b14eafdcf5d>\u001b[0m in \u001b[0;36mminibatch_clustering\u001b[0;34m(self, interaction_list, batch_size)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0musing_full_feature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 pred = self.encoder(\n\u001b[0;32m---> 86\u001b[0;31m                             self.preprocessing_full_ft( [chunk[itemCol], chunk[\"genres\"], chunk[\"year_norm\"], chunk[\"y\"]], \n\u001b[0m\u001b[1;32m     87\u001b[0m                                                         padding_size = wu_size )\n\u001b[1;32m     88\u001b[0m                             ).numpy()\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'genres'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tbl[eval_tbl[\"y\"] <0]"
      ],
      "metadata": {
        "id": "VvVKPp6Pnzhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tbl[\"matched_score\"] = eval_tbl[\"matched_score\"].astype('float')"
      ],
      "metadata": {
        "id": "KHyY576atlL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_tbl[[\"matched_score\", \"y\"]].corr()"
      ],
      "metadata": {
        "id": "gjzBP5jPtAtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYIY1sccKoqF"
      },
      "source": [
        "# END HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z8mwDaKFKp4U"
      },
      "outputs": [],
      "source": [
        "1/0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Warm start evaluation"
      ],
      "metadata": {
        "id": "ijC09qXVaWsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPPnAXS9vBhG"
      },
      "outputs": [],
      "source": [
        "def evaluate_rs(y_true, y_pred, is_return_df = False):\n",
        "    \"\"\"\n",
        "    y_true: dataframe: user_id, item_id, y (rating normailised), only favorite item\n",
        "    y_pred: dataframe: user_id, item_id (just top k item)\n",
        "    return:\n",
        "    precision@k, recall@k\n",
        "    \"\"\"\n",
        "    total1 = y_true.merge(y_pred, on=[userCol, itemCol], how = 'outer', suffixes=('_t', '_p'))\n",
        "    total1['is_pt'] = total1.apply(lambda x: 0 if (np.isnan(x[\"y\"]) or np.isnan(x[\"rank\"]) ) else 1,axis=1)\n",
        "    total = total1.groupby(userCol).agg({\n",
        "        \"y\":'count',\n",
        "        \"rank\":'count',\n",
        "        \"is_pt\": 'sum'\n",
        "        })\n",
        "    total.columns = [\"true_num\", \"predict_num\", \"pred_true_num\"]\n",
        "    total[\"macro_p\"] = total[\"pred_true_num\"]/total[\"predict_num\"]\n",
        "    total[\"macro_r\"] = total[\"pred_true_num\"]/total[\"true_num\"]\n",
        "\n",
        "    total = total[total[\"predict_num\"]>0]\n",
        "\n",
        "    macro_p = total[total[\"predict_num\"]>0][\"macro_p\"].mean()\n",
        "    macro_r = total[total[\"true_num\"]>0][\"macro_r\"].mean()\n",
        "\n",
        "    micro_p = total[\"pred_true_num\"].sum()/total[\"predict_num\"].sum()\n",
        "    micro_r = total[\"pred_true_num\"].sum()/total[\"true_num\"].sum()\n",
        "\n",
        "    print(\"macro_p: \", macro_p, \"; macro_r :\", macro_r)\n",
        "    print(\"micro_p: \", micro_p, \"; micro_r :\", micro_r)\n",
        "\n",
        "    if is_return_df:\n",
        "        return (macro_p, macro_r, micro_p, micro_r), total\n",
        "\n",
        "    return macro_p, macro_r, micro_p, micro_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZKN6iNvJQFj"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "eval_map = map_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_ndcg = ndcg_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_precision = precision_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol ,col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "eval_recall = recall_at_k(y_true, y_pred, col_user = userCol, col_item = itemCol, col_prediction='rating', col_rating=\"rating\", k=top_k)\n",
        "\n",
        "print('K = %f' % top_k)\n",
        "print(\n",
        "    \"MAP:\\t%f\" % eval_map,\n",
        "      \"NDCG:\\t%f\" % eval_ndcg,\n",
        "      \"Precision@K:\\t%f\" % eval_precision,\n",
        "      \"Recall@K:\\t%f\" % eval_recall, sep='\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i91nkjJq793s"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "eval_metrics, eval_df = evaluate_rs(y_true, y_pred, is_return_df= True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "17fHxkHoAQq6"
      ],
      "name": "v2.2_ML20M_sequence.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}