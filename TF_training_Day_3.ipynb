{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF_training_Day_3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLgnWwjV538WMv+AjNe/Bp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanvu0996/TF_cert_training/blob/main/TF_training_Day_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LUYỆN TẬP THỰC HÀNH TENSORFLOW**\n",
        "\n",
        "[DAY 3] TIME SERIES MODELING"
      ],
      "metadata": {
        "id": "DT1HIeuecNwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import urllib\n"
      ],
      "metadata": {
        "id": "N0xLxH4wM_Z6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build and train a neural network to predict sunspot activity using\n",
        "# the Sunspots.csv dataset.\n",
        "#\n",
        "# Your neural network must have an MAE of 0.12 or less on the normalized dataset\n",
        "# for top marks.\n",
        "#\n",
        "# Code for normalizing the data is provided and should not be changed.\n",
        "#\n",
        "# At the bottom of this file, we provide  some testing\n",
        "# code in case you want to check your model.\n",
        "\n",
        "# Note: Do not use lambda layers in your model, they are not supported\n",
        "# on the grading infrastructure.\n"
      ],
      "metadata": {
        "id": "7bkJ_HeOPXye"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n",
        "urllib.request.urlretrieve(url, 'sunspots.csv')\n",
        "\n",
        "time_step = []\n",
        "sunspots = []\n",
        "\n",
        "with open('sunspots.csv') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        sunspots.append(float(row[2]))\n",
        "        time_step.append(int(row[0]))\n",
        "\n",
        "series = np.array(sunspots)"
      ],
      "metadata": {
        "id": "i3qhMeHrM05-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "M4Yff59fMygR"
      },
      "outputs": [],
      "source": [
        "# DO NOT CHANGE THIS CODE\n",
        "def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n",
        "    series = tf.expand_dims(series, axis=-1)\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n",
        "    ds = ds.shuffle(shuffle_buffer)\n",
        "    ds = ds.map(lambda w: (w[:-1], w[1:]))\n",
        "    return ds.batch(batch_size).prefetch(1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# THIS CODE IS USED IN THE TESTER FOR FORECASTING. IF YOU WANT TO TEST YOUR MODEL\n",
        "# BEFORE UPLOADING YOU CAN DO IT WITH THIS\n",
        "# def model_forecast(model, series, window_size):\n",
        "#    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "#    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
        "#    ds = ds.flat_map(lambda w: w.batch(window_size))\n",
        "#    ds = ds.batch(32).prefetch(1)\n",
        "#    forecast = model.predict(ds)\n",
        "#    return forecast\n",
        "\n",
        "\n",
        "# window_size = # YOUR CODE HERE\n",
        "# rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n",
        "# rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]\n",
        "\n",
        "# result = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()\n",
        "\n",
        "## To get the maximum score, your model must have an MAE OF .12 or less.\n",
        "## When you Submit and Test your model, the grading infrastructure\n",
        "## converts the MAE of your model to a score from 0 to 5 as follows:\n",
        "\n",
        "# test_val = 100 * result\n",
        "# score = math.ceil(17 - test_val)\n",
        "# if score > 5:\n",
        "#    score = 5\n",
        "\n",
        "# print(score)"
      ],
      "metadata": {
        "id": "o5LqevFGPeh-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}